{
  "model_name": "LLaVa-Next-8B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_16",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_174753",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8641,
    "num_hallucination": 1359,
    "hallucination_percentage": 13.59
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.95925,
    "precision": 0.9368541905855339,
    "recall": 0.7506899724011039,
    "f1": 0.8335035750766088,
    "auroc": 0.9914506500891419,
    "confusion_matrix": [
      [
        6858,
        55
      ],
      [
        271,
        816
      ]
    ],
    "num_no_hallucination": 6913,
    "num_hallucination": 1087
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.8945,
    "precision": 0.6666666666666666,
    "recall": 0.4485294117647059,
    "f1": 0.5362637362637362,
    "auroc": 0.9048947269880173,
    "confusion_matrix": [
      [
        1667,
        61
      ],
      [
        150,
        122
      ]
    ],
    "num_no_hallucination": 1728,
    "num_hallucination": 272
  },
  "training_history": {
    "train_loss": [
      0.45406942307949066,
      0.28372329342365266,
      0.2606103050112724,
      0.24379697442054749,
      0.23283623293042183,
      0.22302549201250077,
      0.21619385308027267,
      0.2128515364974737,
      0.2084682246595621,
      0.2010494223535061,
      0.19894407293200492,
      0.19634399622678755,
      0.1888583688735962,
      0.18051270785927773,
      0.1854487314671278,
      0.17599448548257351,
      0.1761856843531132,
      0.1742743849903345,
      0.16637849804759025,
      0.16365562607347967,
      0.16864712984859945,
      0.1572244877666235,
      0.1556722495108843,
      0.15129651836305857,
      0.1535729843378067,
      0.15130214846134185,
      0.14603511390835047,
      0.14222899056971072,
      0.1400500098466873,
      0.1326713573038578,
      0.13420443169772625,
      0.13871649079024792,
      0.13504078490287066,
      0.13852954552322627,
      0.13018267045170068,
      0.1259672053307295,
      0.1276322417370975,
      0.12126058197766543,
      0.1246726562306285,
      0.12255126836895942,
      0.11979402508959174,
      0.11962007158994675,
      0.1204181316420436,
      0.1061975507028401,
      0.11108557109162212,
      0.10878795700147748,
      0.10972890049219132,
      0.11041168250143528,
      0.1033106513991952,
      0.10921547951549292
    ],
    "train_acc": [
      0.793,
      0.873125,
      0.8795,
      0.886875,
      0.892375,
      0.896125,
      0.898625,
      0.8995,
      0.9015,
      0.906875,
      0.906625,
      0.907125,
      0.915625,
      0.916125,
      0.91475,
      0.919375,
      0.91925,
      0.918875,
      0.922375,
      0.926625,
      0.92175,
      0.9265,
      0.931625,
      0.9305,
      0.93,
      0.93275,
      0.9325,
      0.9365,
      0.936,
      0.939375,
      0.93875,
      0.937,
      0.934625,
      0.936875,
      0.940125,
      0.943,
      0.941,
      0.943375,
      0.942625,
      0.94375,
      0.943875,
      0.944625,
      0.946875,
      0.950125,
      0.94825,
      0.95,
      0.949125,
      0.9495,
      0.952,
      0.951375
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLaVa_model/llava_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llava_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llava_model_probe/results/query_token_layer_n_2",
    "MODEL_NAME": "LLaVa-Next-8B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_16",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}