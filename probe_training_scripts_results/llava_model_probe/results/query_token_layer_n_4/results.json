{
  "model_name": "LLaVa-Next-8B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_8",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_174700",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8641,
    "num_hallucination": 1359,
    "hallucination_percentage": 13.59
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.9075,
    "precision": 0.7298013245033113,
    "recall": 0.5068997240110396,
    "f1": 0.5982627578718784,
    "auroc": 0.9425719658614204,
    "confusion_matrix": [
      [
        6709,
        204
      ],
      [
        536,
        551
      ]
    ],
    "num_no_hallucination": 6913,
    "num_hallucination": 1087
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.861,
    "precision": 0.4819277108433735,
    "recall": 0.29411764705882354,
    "f1": 0.365296803652968,
    "auroc": 0.8453222869008714,
    "confusion_matrix": [
      [
        1642,
        86
      ],
      [
        192,
        80
      ]
    ],
    "num_no_hallucination": 1728,
    "num_hallucination": 272
  },
  "training_history": {
    "train_loss": [
      0.4933461198806763,
      0.3325189087986946,
      0.3161835039258003,
      0.30820634865760804,
      0.297052101790905,
      0.2898340644240379,
      0.28612297278642657,
      0.2823047362565994,
      0.2760077410340309,
      0.27441143462061884,
      0.273058733612299,
      0.2720801675319672,
      0.2660072790980339,
      0.26712140303850174,
      0.26495263144373893,
      0.25857765445113184,
      0.2610914559960365,
      0.2595931745171547,
      0.258937708735466,
      0.2556133865714073,
      0.2508978476822376,
      0.25271156522631644,
      0.2533207637667656,
      0.24597564509510994,
      0.2511493733227253,
      0.246611988902092,
      0.24585740810632706,
      0.24354104307293892,
      0.2413480395078659,
      0.23940814310312272,
      0.2360909194946289,
      0.23741504195332527,
      0.24000323578715324,
      0.2346959935426712,
      0.23413263961672784,
      0.23233583736419677,
      0.2360483358502388,
      0.23212181320786476,
      0.23130921351909636,
      0.22879405450820922,
      0.22658983927965165,
      0.2254379572570324,
      0.22422360479831696,
      0.2221232741177082,
      0.22820411759614945,
      0.22112131416797637,
      0.21885975274443625,
      0.2133704229593277,
      0.2211006591618061,
      0.2188952005803585
    ],
    "train_acc": [
      0.765875,
      0.862125,
      0.86925,
      0.87075,
      0.874,
      0.8725,
      0.875875,
      0.88,
      0.87675,
      0.877375,
      0.874875,
      0.877625,
      0.8815,
      0.880875,
      0.8785,
      0.882375,
      0.880125,
      0.8845,
      0.88275,
      0.883125,
      0.88675,
      0.88325,
      0.883125,
      0.885625,
      0.887125,
      0.88675,
      0.88625,
      0.88525,
      0.884125,
      0.893125,
      0.8935,
      0.893875,
      0.890875,
      0.893125,
      0.888125,
      0.892625,
      0.890125,
      0.890875,
      0.894125,
      0.896375,
      0.895875,
      0.897,
      0.89675,
      0.895875,
      0.895125,
      0.89975,
      0.89925,
      0.9,
      0.89825,
      0.898125
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLaVa_model/llava_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llava_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llava_model_probe/results/query_token_layer_n_4",
    "MODEL_NAME": "LLaVa-Next-8B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_8",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}