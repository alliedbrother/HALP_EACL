{
  "model_name": "LLaVa-Next-8B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_0",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_173959",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8641,
    "num_hallucination": 1359,
    "hallucination_percentage": 13.59
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.872,
    "precision": 0.7299270072992701,
    "recall": 0.09199632014719411,
    "f1": 0.16339869281045752,
    "auroc": 0.8488722565953429,
    "confusion_matrix": [
      [
        6876,
        37
      ],
      [
        987,
        100
      ]
    ],
    "num_no_hallucination": 6913,
    "num_hallucination": 1087
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.8555,
    "precision": 0.3111111111111111,
    "recall": 0.051470588235294115,
    "f1": 0.08832807570977919,
    "auroc": 0.603717745778867,
    "confusion_matrix": [
      [
        1697,
        31
      ],
      [
        258,
        14
      ]
    ],
    "num_no_hallucination": 1728,
    "num_hallucination": 272
  },
  "training_history": {
    "train_loss": [
      0.537313464999199,
      0.4120807020664215,
      0.4052159493565559,
      0.39483281755447386,
      0.39022550266981126,
      0.38841158950328825,
      0.3825481070280075,
      0.37574183678627016,
      0.3766264260411262,
      0.3707081480622292,
      0.366794443488121,
      0.365985172688961,
      0.3655714824199677,
      0.3580287743806839,
      0.3603205417394638,
      0.36117358040809633,
      0.3549140217900276,
      0.35474463605880735,
      0.3530265083909035,
      0.348685709297657,
      0.3468909839987755,
      0.34593651777505874,
      0.34333611524105073,
      0.341864919424057,
      0.3381558062434196,
      0.33802944296598436,
      0.3323911539912224,
      0.3374221988916397,
      0.33386043828725814,
      0.33235565888881685,
      0.3249763541817665,
      0.3279944141507149,
      0.3276135375499725,
      0.3242420233488083,
      0.3215243493914604,
      0.32388284599781036,
      0.3214148151278496,
      0.32348495799303056,
      0.3139467241168022,
      0.31479805597662924,
      0.3169780490994453,
      0.3151108349263668,
      0.3147851975560188,
      0.3145976835489273,
      0.31389691907167433,
      0.31011772710084917,
      0.3089080439209938,
      0.3114989785850048,
      0.3079714975357056,
      0.30641809332370756
    ],
    "train_acc": [
      0.758125,
      0.8615,
      0.862625,
      0.86325,
      0.8635,
      0.8635,
      0.863375,
      0.864625,
      0.8645,
      0.865125,
      0.8655,
      0.864875,
      0.865375,
      0.865625,
      0.865625,
      0.865,
      0.86475,
      0.86425,
      0.86625,
      0.865375,
      0.867125,
      0.865375,
      0.86725,
      0.867625,
      0.869125,
      0.867,
      0.868,
      0.866125,
      0.8675,
      0.870125,
      0.87325,
      0.869,
      0.870625,
      0.870375,
      0.876125,
      0.86975,
      0.872125,
      0.871,
      0.87325,
      0.87125,
      0.873625,
      0.875875,
      0.8735,
      0.87375,
      0.8755,
      0.871375,
      0.876125,
      0.873,
      0.87475,
      0.875
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLaVa_model/llava_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llava_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llava_model_probe/results/vision_token_layer0",
    "MODEL_NAME": "LLaVa-Next-8B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_0",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}