{
  "model_name": "LLaVa-Next-8B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_8",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_174051",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8641,
    "num_hallucination": 1359,
    "hallucination_percentage": 13.59
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.882125,
    "precision": 0.78125,
    "recall": 0.18399264029438822,
    "f1": 0.29784065524944153,
    "auroc": 0.9235242828099693,
    "confusion_matrix": [
      [
        6857,
        56
      ],
      [
        887,
        200
      ]
    ],
    "num_no_hallucination": 6913,
    "num_hallucination": 1087
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.851,
    "precision": 0.32432432432432434,
    "recall": 0.08823529411764706,
    "f1": 0.13872832369942195,
    "auroc": 0.6184863919526143,
    "confusion_matrix": [
      [
        1678,
        50
      ],
      [
        248,
        24
      ]
    ],
    "num_no_hallucination": 1728,
    "num_hallucination": 272
  },
  "training_history": {
    "train_loss": [
      0.522649998486042,
      0.4067750428915024,
      0.39015215963125227,
      0.37981196492910385,
      0.37115007001161576,
      0.36218843680620194,
      0.3570380267500877,
      0.3470515542626381,
      0.34253070533275604,
      0.3411978493332863,
      0.331983074426651,
      0.330258161008358,
      0.3241453939676285,
      0.3219392158985138,
      0.3158778437077999,
      0.31372277384996416,
      0.30986853456497193,
      0.3061976564526558,
      0.3022394859790802,
      0.30005011826753614,
      0.29511398828029634,
      0.2936381914317608,
      0.29154595944285394,
      0.28464785066246984,
      0.2859544711112976,
      0.28595574441552163,
      0.2799715632498264,
      0.2775781375169754,
      0.2764670287668705,
      0.27373388504981994,
      0.2716485553979874,
      0.27389741024374964,
      0.2684691221415997,
      0.274400241792202,
      0.2655404319763184,
      0.263406883507967,
      0.26208936899900437,
      0.26365032002329825,
      0.26076947259902955,
      0.2587615080177784,
      0.25437165290117264,
      0.25976296004652977,
      0.25474675595760343,
      0.25189657041430474,
      0.25007228609919546,
      0.2486886769235134,
      0.24553689244389534,
      0.24821761265397072,
      0.24358298653364183,
      0.24423361289501191
    ],
    "train_acc": [
      0.776625,
      0.860375,
      0.85975,
      0.86375,
      0.862625,
      0.86225,
      0.86275,
      0.86475,
      0.864875,
      0.86525,
      0.867875,
      0.8665,
      0.868875,
      0.865375,
      0.867375,
      0.8715,
      0.869375,
      0.870625,
      0.870625,
      0.871,
      0.871875,
      0.874625,
      0.872,
      0.874,
      0.87625,
      0.877875,
      0.875,
      0.878375,
      0.879125,
      0.87725,
      0.8805,
      0.879375,
      0.88125,
      0.878625,
      0.87925,
      0.881125,
      0.880125,
      0.882375,
      0.885625,
      0.885625,
      0.886625,
      0.88525,
      0.88925,
      0.88575,
      0.884375,
      0.884625,
      0.886625,
      0.887,
      0.883875,
      0.8885
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLaVa_model/llava_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llava_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llava_model_probe/results/vision_token_layer_n_4",
    "MODEL_NAME": "LLaVa-Next-8B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_8",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}