{
  "model_name": "LLaVa-Next-8B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_0",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_174608",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8641,
    "num_hallucination": 1359,
    "hallucination_percentage": 13.59
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.864125,
    "precision": 0.0,
    "recall": 0.0,
    "f1": 0.0,
    "auroc": 0.5,
    "confusion_matrix": [
      [
        6913,
        0
      ],
      [
        1087,
        0
      ]
    ],
    "num_no_hallucination": 6913,
    "num_hallucination": 1087
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.864,
    "precision": 0.0,
    "recall": 0.0,
    "f1": 0.0,
    "auroc": 0.49962554466230935,
    "confusion_matrix": [
      [
        1728,
        0
      ],
      [
        272,
        0
      ]
    ],
    "num_no_hallucination": 1728,
    "num_hallucination": 272
  },
  "training_history": {
    "train_loss": [
      0.5481119788885117,
      0.4266689864397049,
      0.4178983198404312,
      0.41782283294200895,
      0.4094375942349434,
      0.4081433676481247,
      0.40768562245368956,
      0.4057877267599106,
      0.4073734652400017,
      0.40641029143333435,
      0.40328884100914003,
      0.40277596580982206,
      0.4045991842150688,
      0.40142647409439086,
      0.4042067038416862,
      0.40160859656333925,
      0.4030406963825226,
      0.40220168721675875,
      0.401628765642643,
      0.4021003057956696,
      0.4015248665213585,
      0.40232512092590333,
      0.40253291791677476,
      0.4024273532629013,
      0.3998431735038757,
      0.4024341094493866,
      0.40097453379631043,
      0.40055817258358,
      0.4009803481698036,
      0.40038121795654297,
      0.4005653755068779,
      0.4020492259860039,
      0.400363439142704,
      0.4005457143187523,
      0.4001139943599701,
      0.399756367623806,
      0.3993966928124428,
      0.3997702687382698,
      0.3990737694501877,
      0.4004022598862648,
      0.39958087384700774,
      0.3996792022585869,
      0.3998257237672806,
      0.3999746181368828,
      0.4002474319934845,
      0.39925043016672135,
      0.4009555832147598,
      0.39924960976839063,
      0.3996583315730095,
      0.3996132904291153
    ],
    "train_acc": [
      0.742625,
      0.857875,
      0.862875,
      0.8635,
      0.864,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125,
      0.864125
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLaVa_model/llava_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llava_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llava_model_probe/results/query_token_layer0",
    "MODEL_NAME": "LLaVa-Next-8B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_0",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}