{
  "model_name": "LLaVa-Next-8B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_16",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_174142",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8641,
    "num_hallucination": 1359,
    "hallucination_percentage": 13.59
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.906625,
    "precision": 0.7786885245901639,
    "recall": 0.43698252069917204,
    "f1": 0.5598114319387154,
    "auroc": 0.952188728594354,
    "confusion_matrix": [
      [
        6778,
        135
      ],
      [
        612,
        475
      ]
    ],
    "num_no_hallucination": 6913,
    "num_hallucination": 1087
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.821,
    "precision": 0.24404761904761904,
    "recall": 0.15073529411764705,
    "f1": 0.18636363636363637,
    "auroc": 0.6191895595043573,
    "confusion_matrix": [
      [
        1601,
        127
      ],
      [
        231,
        41
      ]
    ],
    "num_no_hallucination": 1728,
    "num_hallucination": 272
  },
  "training_history": {
    "train_loss": [
      0.5328531732559204,
      0.4017051437497139,
      0.3806220383644104,
      0.36028568279743195,
      0.34434230148792266,
      0.32880982184410096,
      0.31923085460066797,
      0.304388042986393,
      0.30455155861377714,
      0.29396864360570907,
      0.284340920060873,
      0.2850012049376965,
      0.27842440420389175,
      0.2771324424147606,
      0.26636783012747767,
      0.2642611059546471,
      0.2588687167465687,
      0.25579330998659133,
      0.2502890628874302,
      0.2512822912931442,
      0.23842206606268881,
      0.24217618879675865,
      0.23563822957873345,
      0.24152113100886344,
      0.23542244410514832,
      0.23657364615797996,
      0.22663675147294998,
      0.2248468983769417,
      0.2251037250459194,
      0.21982311752438546,
      0.22355532264709474,
      0.21983087518811226,
      0.21414081031084062,
      0.21378885731101036,
      0.21529396265745163,
      0.21640034773945807,
      0.21513484805822372,
      0.2135101971924305,
      0.21204500317573546,
      0.20892910739779472,
      0.2052368683516979,
      0.20487354046106337,
      0.2034003967642784,
      0.2038850381076336,
      0.20264990890026094,
      0.19362223824858665,
      0.2025441512465477,
      0.20310229709744454,
      0.1992945503294468,
      0.1975146621018648
    ],
    "train_acc": [
      0.768875,
      0.85475,
      0.859875,
      0.862875,
      0.864,
      0.86775,
      0.8695,
      0.87375,
      0.86975,
      0.872875,
      0.878,
      0.876875,
      0.880875,
      0.878125,
      0.880625,
      0.880625,
      0.882125,
      0.8845,
      0.886375,
      0.884875,
      0.887375,
      0.888625,
      0.890125,
      0.885875,
      0.892625,
      0.89075,
      0.88825,
      0.892375,
      0.887875,
      0.894875,
      0.8925,
      0.89425,
      0.89525,
      0.894125,
      0.896125,
      0.894875,
      0.89625,
      0.89375,
      0.895,
      0.899,
      0.900125,
      0.899125,
      0.899625,
      0.903,
      0.89575,
      0.903,
      0.900125,
      0.89725,
      0.900125,
      0.899
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLaVa_model/llava_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llava_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llava_model_probe/results/vision_token_layer_n_2",
    "MODEL_NAME": "LLaVa-Next-8B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_16",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}