{
  "model_name": "LLaVa-Next-8B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_31",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_174328",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8641,
    "num_hallucination": 1359,
    "hallucination_percentage": 13.59
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.904625,
    "precision": 0.86,
    "recall": 0.3560257589696412,
    "f1": 0.5035783994795056,
    "auroc": 0.9521362296094009,
    "confusion_matrix": [
      [
        6850,
        63
      ],
      [
        700,
        387
      ]
    ],
    "num_no_hallucination": 6913,
    "num_hallucination": 1087
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.832,
    "precision": 0.2647058823529412,
    "recall": 0.1323529411764706,
    "f1": 0.17647058823529413,
    "auroc": 0.6270329095179739,
    "confusion_matrix": [
      [
        1628,
        100
      ],
      [
        236,
        36
      ]
    ],
    "num_no_hallucination": 1728,
    "num_hallucination": 272
  },
  "training_history": {
    "train_loss": [
      0.5283402265310287,
      0.40051615285873415,
      0.3772744317650795,
      0.35632935839891433,
      0.33930135470628736,
      0.3182674958705902,
      0.3127084221243858,
      0.2983350006043911,
      0.2878863792419434,
      0.2802319900095463,
      0.27087224382162095,
      0.26951122882962225,
      0.26667435508966447,
      0.25490438717603686,
      0.25203280806541445,
      0.2523953684568405,
      0.24073735159635543,
      0.2424890892505646,
      0.23389786294102669,
      0.23084550827741623,
      0.2277901338338852,
      0.2314862710237503,
      0.2262234292924404,
      0.22055771708488464,
      0.22226466366648673,
      0.21457931089401244,
      0.2214233547747135,
      0.21316281166672707,
      0.21581776213645934,
      0.21076742881536484,
      0.20417840909957885,
      0.21073997892439367,
      0.21094667372107506,
      0.20469106316566468,
      0.20062228301167487,
      0.2039620506465435,
      0.20415064135193825,
      0.19951507346332073,
      0.19873997822403908,
      0.19814731156826018,
      0.1945390495955944,
      0.19019326692819596,
      0.19187030947208406,
      0.19642885503172874,
      0.19406290757656097,
      0.19493086543679236,
      0.192744084328413,
      0.1873638836145401,
      0.19005813190340995,
      0.19458602061867714
    ],
    "train_acc": [
      0.76625,
      0.857875,
      0.859,
      0.864125,
      0.864875,
      0.8685,
      0.870125,
      0.873,
      0.87325,
      0.8765,
      0.8795,
      0.88175,
      0.879875,
      0.88175,
      0.883625,
      0.884875,
      0.885625,
      0.887875,
      0.88925,
      0.889375,
      0.888125,
      0.890875,
      0.890875,
      0.89375,
      0.890875,
      0.893375,
      0.891375,
      0.89475,
      0.8925,
      0.898125,
      0.89625,
      0.897125,
      0.895375,
      0.89875,
      0.8965,
      0.898125,
      0.9,
      0.8985,
      0.90025,
      0.89825,
      0.899,
      0.90425,
      0.902875,
      0.901625,
      0.899375,
      0.900375,
      0.898625,
      0.9045,
      0.902375,
      0.89825
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLaVa_model/llava_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llava_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llava_model_probe/results/vision_token_layer_n",
    "MODEL_NAME": "LLaVa-Next-8B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_31",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}