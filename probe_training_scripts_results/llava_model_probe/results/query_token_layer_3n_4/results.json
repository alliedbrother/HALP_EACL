{
  "model_name": "LLaVa-Next-8B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_24",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_174846",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8641,
    "num_hallucination": 1359,
    "hallucination_percentage": 13.59
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.94875,
    "precision": 0.9436435124508519,
    "recall": 0.6623735050597976,
    "f1": 0.7783783783783784,
    "auroc": 0.9858091717124025,
    "confusion_matrix": [
      [
        6870,
        43
      ],
      [
        367,
        720
      ]
    ],
    "num_no_hallucination": 6913,
    "num_hallucination": 1087
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.8865,
    "precision": 0.6470588235294118,
    "recall": 0.3639705882352941,
    "f1": 0.46588235294117647,
    "auroc": 0.9052819478485838,
    "confusion_matrix": [
      [
        1674,
        54
      ],
      [
        173,
        99
      ]
    ],
    "num_no_hallucination": 1728,
    "num_hallucination": 272
  },
  "training_history": {
    "train_loss": [
      0.4619929825663567,
      0.28544666785001754,
      0.26387533628940585,
      0.24923586505651474,
      0.24115227788686752,
      0.2338520056605339,
      0.22072526001930237,
      0.2149714009463787,
      0.2166867041885853,
      0.21340463575720786,
      0.21009674993157387,
      0.20631206652522088,
      0.19983888681232928,
      0.2041807777583599,
      0.19597166642546654,
      0.188714861035347,
      0.1877857033610344,
      0.18811510190367697,
      0.18498018757998944,
      0.17803529522567987,
      0.18021140387654305,
      0.17277961957454682,
      0.1736532813310623,
      0.1735986229479313,
      0.170160040974617,
      0.1602890684902668,
      0.16464585140347482,
      0.1628328008800745,
      0.1590659361705184,
      0.15728698574006558,
      0.15936370094120503,
      0.15395825231075286,
      0.1543967247530818,
      0.15143263460695744,
      0.1464633138924837,
      0.14606883376464247,
      0.1442558078020811,
      0.14552554953098298,
      0.14274110551923513,
      0.14723449556529522,
      0.13873490875959396,
      0.135938731610775,
      0.14272811317443848,
      0.13501746667921544,
      0.13623231174051761,
      0.12878888654708862,
      0.136976540312171,
      0.13247950308024883,
      0.1316045652255416,
      0.12636652034521104
    ],
    "train_acc": [
      0.78225,
      0.871125,
      0.8795,
      0.887125,
      0.88825,
      0.894,
      0.894125,
      0.904375,
      0.895625,
      0.90175,
      0.90025,
      0.903375,
      0.9075,
      0.904875,
      0.91325,
      0.91525,
      0.9135,
      0.91325,
      0.913625,
      0.91725,
      0.912125,
      0.91725,
      0.919125,
      0.92325,
      0.919625,
      0.923125,
      0.923,
      0.9275,
      0.9275,
      0.92725,
      0.925875,
      0.931125,
      0.93075,
      0.93225,
      0.93325,
      0.932375,
      0.936,
      0.9355,
      0.937125,
      0.93375,
      0.938375,
      0.93975,
      0.93475,
      0.9405,
      0.937875,
      0.94225,
      0.938375,
      0.940125,
      0.941125,
      0.94375
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLaVa_model/llava_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llava_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llava_model_probe/results/query_token_layer_3n_4",
    "MODEL_NAME": "LLaVa-Next-8B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_24",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}