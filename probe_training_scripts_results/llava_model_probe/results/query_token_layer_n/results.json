{
  "model_name": "LLaVa-Next-8B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_31",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_174939",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8641,
    "num_hallucination": 1359,
    "hallucination_percentage": 13.59
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.943125,
    "precision": 0.8599088838268792,
    "recall": 0.6945722171113156,
    "f1": 0.7684478371501272,
    "auroc": 0.9807945538391398,
    "confusion_matrix": [
      [
        6790,
        123
      ],
      [
        332,
        755
      ]
    ],
    "num_no_hallucination": 6913,
    "num_hallucination": 1087
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.8905,
    "precision": 0.6199095022624435,
    "recall": 0.5036764705882353,
    "f1": 0.5557809330628803,
    "auroc": 0.9026118259803924,
    "confusion_matrix": [
      [
        1644,
        84
      ],
      [
        135,
        137
      ]
    ],
    "num_no_hallucination": 1728,
    "num_hallucination": 272
  },
  "training_history": {
    "train_loss": [
      0.46347722798585894,
      0.2815711544156074,
      0.2639472822844982,
      0.2552638688385487,
      0.2369406980574131,
      0.23376958349347116,
      0.22665200716257095,
      0.2202095081806183,
      0.2164945842027664,
      0.21954363398253918,
      0.20721493858098983,
      0.20598702086508275,
      0.2060290701240301,
      0.2049537313878536,
      0.19831269657611847,
      0.19770715636014938,
      0.19432925683259963,
      0.19627236552536487,
      0.18869555251300335,
      0.1850653851926327,
      0.18278286299109459,
      0.18151318344473838,
      0.18059708140790462,
      0.17868930245935916,
      0.17849234783649445,
      0.17649600461125373,
      0.17133984778821468,
      0.17153690546005965,
      0.1698155352026224,
      0.16453690508008004,
      0.16583877877891065,
      0.16359132365882398,
      0.16106827554851771,
      0.16598836502432823,
      0.15906230290979148,
      0.16210423670709134,
      0.15515435788035392,
      0.1559525720179081,
      0.15439671044051648,
      0.15476819570362568,
      0.14550515915453435,
      0.1437933773994446,
      0.1488796481192112,
      0.1489346448779106,
      0.14526921761035919,
      0.14446476729214192,
      0.14546141223609446,
      0.1414068852029741,
      0.14233853869885207,
      0.13649489034712314
    ],
    "train_acc": [
      0.785875,
      0.873875,
      0.876875,
      0.87975,
      0.885125,
      0.89075,
      0.893,
      0.900125,
      0.899375,
      0.8935,
      0.905625,
      0.903375,
      0.903125,
      0.902625,
      0.9075,
      0.91075,
      0.91125,
      0.911125,
      0.91425,
      0.916,
      0.918125,
      0.915125,
      0.917125,
      0.914875,
      0.91975,
      0.921,
      0.922875,
      0.924,
      0.923625,
      0.92675,
      0.924125,
      0.923,
      0.92875,
      0.92525,
      0.925,
      0.925875,
      0.929875,
      0.930625,
      0.928,
      0.929125,
      0.932125,
      0.934875,
      0.931625,
      0.92975,
      0.931625,
      0.935625,
      0.932125,
      0.93675,
      0.9345,
      0.937
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLaVa_model/llava_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llava_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llava_model_probe/results/query_token_layer_n",
    "MODEL_NAME": "LLaVa-Next-8B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_31",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}