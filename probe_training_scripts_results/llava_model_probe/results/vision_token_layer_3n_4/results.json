{
  "model_name": "LLaVa-Next-8B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_24",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_174234",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8641,
    "num_hallucination": 1359,
    "hallucination_percentage": 13.59
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.90525,
    "precision": 0.8145315487571702,
    "recall": 0.39190432382704693,
    "f1": 0.529192546583851,
    "auroc": 0.9497239378470572,
    "confusion_matrix": [
      [
        6816,
        97
      ],
      [
        661,
        426
      ]
    ],
    "num_no_hallucination": 6913,
    "num_hallucination": 1087
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.822,
    "precision": 0.23417721518987342,
    "recall": 0.13602941176470587,
    "f1": 0.17209302325581396,
    "auroc": 0.6193959354575164,
    "confusion_matrix": [
      [
        1607,
        121
      ],
      [
        235,
        37
      ]
    ],
    "num_no_hallucination": 1728,
    "num_hallucination": 272
  },
  "training_history": {
    "train_loss": [
      0.5478110419511795,
      0.4088346853852272,
      0.37664890676736834,
      0.3567077776193619,
      0.3421310743093491,
      0.3270423159003258,
      0.31081844013929366,
      0.29870703637599944,
      0.2944618107378483,
      0.2818775799870491,
      0.2772881446480751,
      0.2692613300681114,
      0.2627925896048546,
      0.25629721021652224,
      0.2554764959812164,
      0.2513896593153477,
      0.24856988668441773,
      0.24546596857905387,
      0.2391375499367714,
      0.23765855056047439,
      0.23552638459205627,
      0.23410003760457038,
      0.22981048336625098,
      0.22827842056751252,
      0.22570141664147378,
      0.22326036715507508,
      0.2238210507631302,
      0.21450699517130853,
      0.2176812706589699,
      0.21343355771899222,
      0.21229787001013756,
      0.2116219045817852,
      0.2101190924048424,
      0.20924463960528375,
      0.2068982280790806,
      0.20506596618890763,
      0.20564727333188057,
      0.19890891197323798,
      0.19960128885507583,
      0.20089400273561478,
      0.19977724704146385,
      0.1976161539554596,
      0.1944045267999172,
      0.20046563428640365,
      0.1960243333876133,
      0.19385515862703323,
      0.19701146844029427,
      0.19426822343468667,
      0.19123791894316675,
      0.19426829420030117
    ],
    "train_acc": [
      0.74325,
      0.856625,
      0.86,
      0.86375,
      0.865625,
      0.866125,
      0.869875,
      0.874625,
      0.872875,
      0.87725,
      0.88125,
      0.877375,
      0.8815,
      0.8825,
      0.885375,
      0.8845,
      0.889375,
      0.889125,
      0.886,
      0.889125,
      0.888375,
      0.890875,
      0.89025,
      0.891,
      0.891875,
      0.892625,
      0.8915,
      0.896,
      0.893375,
      0.89475,
      0.89275,
      0.8975,
      0.897125,
      0.8955,
      0.9,
      0.89775,
      0.90025,
      0.902,
      0.898,
      0.897,
      0.8975,
      0.89925,
      0.900875,
      0.900875,
      0.90475,
      0.901625,
      0.900125,
      0.89925,
      0.903875,
      0.90175
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLaVa_model/llava_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llava_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llava_model_probe/results/vision_token_layer_3n_4",
    "MODEL_NAME": "LLaVa-Next-8B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_24",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}