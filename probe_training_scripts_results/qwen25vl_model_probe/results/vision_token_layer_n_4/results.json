{
  "model_name": "Qwen2.5-VL-7B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_7",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3584,
  "timestamp": "20251003_182124",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9394,
    "num_hallucination": 606,
    "hallucination_percentage": 6.0600000000000005
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.962625,
    "precision": 0.7348484848484849,
    "recall": 0.6,
    "f1": 0.6606129398410897,
    "auroc": 0.9778547372608735,
    "confusion_matrix": [
      [
        7410,
        105
      ],
      [
        194,
        291
      ]
    ],
    "num_no_hallucination": 7515,
    "num_hallucination": 485
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.919,
    "precision": 0.23376623376623376,
    "recall": 0.1487603305785124,
    "f1": 0.18181818181818182,
    "auroc": 0.659325120184378,
    "confusion_matrix": [
      [
        1820,
        59
      ],
      [
        103,
        18
      ]
    ],
    "num_no_hallucination": 1879,
    "num_hallucination": 121
  },
  "training_history": {
    "train_loss": [
      0.4679375680088997,
      0.2335607197880745,
      0.20812235893309117,
      0.1881053011417389,
      0.16824625985324382,
      0.15893421509861946,
      0.14991886349767447,
      0.14051022850722075,
      0.1325449805110693,
      0.12761235527694226,
      0.12207607825100422,
      0.11679815734177827,
      0.11343261387199163,
      0.11210530844330788,
      0.10320272960513831,
      0.10091469372436404,
      0.0952164959460497,
      0.10102992438524962,
      0.09746958246827125,
      0.09310801632702351,
      0.09373541101813317,
      0.09192411119677127,
      0.09006939177587628,
      0.08543129028193652,
      0.0912363125756383,
      0.08856629686057568,
      0.08346978997066618,
      0.08041005059704184,
      0.079919947296381,
      0.08234120320156217,
      0.08109944781288504,
      0.0797795907575637,
      0.07849600104615093,
      0.07728658520616591,
      0.07939512385055422,
      0.07538942140713334,
      0.07607203959207982,
      0.077596486562863,
      0.07192349502630532,
      0.07244942607916892,
      0.07285800973512233,
      0.0749649918191135,
      0.07280846345750615,
      0.07149289551749825,
      0.07452089164499194,
      0.072408054292202,
      0.07059114400297403,
      0.07077792232297361,
      0.07076788199320436,
      0.07155158544704318
    ],
    "train_acc": [
      0.8,
      0.93525,
      0.93575,
      0.93775,
      0.940875,
      0.940875,
      0.940625,
      0.944625,
      0.946125,
      0.9465,
      0.94975,
      0.949625,
      0.95075,
      0.950875,
      0.954625,
      0.95275,
      0.953375,
      0.953875,
      0.953875,
      0.954625,
      0.959125,
      0.956625,
      0.958125,
      0.958375,
      0.954375,
      0.958375,
      0.95825,
      0.959,
      0.962125,
      0.959625,
      0.960125,
      0.961125,
      0.961875,
      0.9605,
      0.960125,
      0.961625,
      0.95975,
      0.96,
      0.9635,
      0.961125,
      0.961375,
      0.963875,
      0.963,
      0.962875,
      0.960875,
      0.9645,
      0.963875,
      0.962375,
      0.961625,
      0.963
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Qwen25_VL/qwen25_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/qwen25vl_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/qwen25vl_model_probe/results/vision_token_layer_n_4",
    "MODEL_NAME": "Qwen2.5-VL-7B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_7",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}