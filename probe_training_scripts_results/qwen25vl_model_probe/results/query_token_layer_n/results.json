{
  "model_name": "Qwen2.5-VL-7B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_27",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3584,
  "timestamp": "20251003_182838",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9394,
    "num_hallucination": 606,
    "hallucination_percentage": 6.0600000000000005
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.97375,
    "precision": 0.9421221864951769,
    "recall": 0.6041237113402061,
    "f1": 0.7361809045226131,
    "auroc": 0.9932451248705338,
    "confusion_matrix": [
      [
        7497,
        18
      ],
      [
        192,
        293
      ]
    ],
    "num_no_hallucination": 7515,
    "num_hallucination": 485
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.9485,
    "precision": 0.640625,
    "recall": 0.33884297520661155,
    "f1": 0.44324324324324327,
    "auroc": 0.9149978668097589,
    "confusion_matrix": [
      [
        1856,
        23
      ],
      [
        80,
        41
      ]
    ],
    "num_no_hallucination": 1879,
    "num_hallucination": 121
  },
  "training_history": {
    "train_loss": [
      0.42589552396535874,
      0.18942919319868087,
      0.1693193484544754,
      0.16179609203338624,
      0.15253984028100967,
      0.14471486764401198,
      0.13937395285815002,
      0.13712031149864196,
      0.1345130435079336,
      0.13125507479161025,
      0.127370320353657,
      0.127008424654603,
      0.12696072894334792,
      0.12249297229200602,
      0.11820018973201513,
      0.11611531595140695,
      0.1175610383450985,
      0.1139989521279931,
      0.11369564823433757,
      0.11002484115213156,
      0.1106579791456461,
      0.10962583234161138,
      0.10536442897468805,
      0.10791755083948373,
      0.10323701657354832,
      0.10419972592592239,
      0.10204380703717471,
      0.09531154389306903,
      0.09781578979641199,
      0.1001223635673523,
      0.09531368397921323,
      0.09293653805740178,
      0.08837596897594631,
      0.09660724786296487,
      0.08727617728710174,
      0.09104357914626598,
      0.0825954988412559,
      0.0888523585125804,
      0.08541399452276528,
      0.08501440611854195,
      0.08074508088454604,
      0.0861788169760257,
      0.07841942404769361,
      0.08023578913137316,
      0.07922787410020828,
      0.08098295304179191,
      0.07909505492448807,
      0.07512792727723717,
      0.0745848364206031,
      0.07337665714975447
    ],
    "train_acc": [
      0.82775,
      0.930625,
      0.936125,
      0.935125,
      0.938375,
      0.941625,
      0.94125,
      0.94425,
      0.94175,
      0.94575,
      0.946625,
      0.943875,
      0.94525,
      0.945875,
      0.949125,
      0.948625,
      0.948625,
      0.951125,
      0.9515,
      0.952625,
      0.951875,
      0.954,
      0.95425,
      0.95225,
      0.954375,
      0.955375,
      0.954125,
      0.957875,
      0.957625,
      0.955625,
      0.959875,
      0.959875,
      0.96,
      0.958125,
      0.9635,
      0.960125,
      0.963875,
      0.95875,
      0.962875,
      0.9605,
      0.965375,
      0.962,
      0.9655,
      0.964375,
      0.964875,
      0.9655,
      0.9635,
      0.9675,
      0.966125,
      0.96675
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Qwen25_VL/qwen25_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/qwen25vl_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/qwen25vl_model_probe/results/query_token_layer_n",
    "MODEL_NAME": "Qwen2.5-VL-7B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_27",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}