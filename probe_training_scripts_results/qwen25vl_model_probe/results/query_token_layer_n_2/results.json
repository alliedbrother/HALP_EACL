{
  "model_name": "Qwen2.5-VL-7B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_14",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3584,
  "timestamp": "20251003_182653",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9394,
    "num_hallucination": 606,
    "hallucination_percentage": 6.0600000000000005
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.956375,
    "precision": 0.6827956989247311,
    "recall": 0.5237113402061856,
    "f1": 0.5927654609101517,
    "auroc": 0.9705614201150963,
    "confusion_matrix": [
      [
        7397,
        118
      ],
      [
        231,
        254
      ]
    ],
    "num_no_hallucination": 7515,
    "num_hallucination": 485
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.9275,
    "precision": 0.35365853658536583,
    "recall": 0.2396694214876033,
    "f1": 0.2857142857142857,
    "auroc": 0.8794109755936647,
    "confusion_matrix": [
      [
        1826,
        53
      ],
      [
        92,
        29
      ]
    ],
    "num_no_hallucination": 1879,
    "num_hallucination": 121
  },
  "training_history": {
    "train_loss": [
      0.43127618545293805,
      0.20661643670499324,
      0.18916502965986728,
      0.18053918088972568,
      0.17967067241668702,
      0.17116583742201327,
      0.16423828050494194,
      0.16347144788503648,
      0.16388628423213958,
      0.16009797649085522,
      0.15912559117376804,
      0.15463745893537997,
      0.15097591516375541,
      0.1469965208917856,
      0.1490784858316183,
      0.14353369577974082,
      0.14357529447972775,
      0.14085408586263656,
      0.13782187370210885,
      0.13457468709349632,
      0.1357771802097559,
      0.13380962200462818,
      0.13138254510611297,
      0.1289022421836853,
      0.12951137814670802,
      0.12795831827819348,
      0.12633972261846066,
      0.12228082508593797,
      0.12489422520250082,
      0.12220611690729856,
      0.12175260323286057,
      0.12040879049152135,
      0.11799502346664667,
      0.11567124305665492,
      0.11647486239671707,
      0.10971875072270632,
      0.11763730850815773,
      0.11199101562052965,
      0.11523374937474727,
      0.10482088108360767,
      0.10965393529459834,
      0.1076612056158483,
      0.10498809461295605,
      0.10653283454477787,
      0.10626278211176396,
      0.10041932079568505,
      0.1052621297314763,
      0.1004881705865264,
      0.09858446140959859,
      0.1019437364935875
    ],
    "train_acc": [
      0.83175,
      0.933875,
      0.933,
      0.934375,
      0.935375,
      0.9385,
      0.938625,
      0.937125,
      0.93875,
      0.938,
      0.93925,
      0.94125,
      0.9405,
      0.940625,
      0.94025,
      0.943125,
      0.943125,
      0.942125,
      0.943125,
      0.94425,
      0.946125,
      0.9435,
      0.946125,
      0.94675,
      0.944875,
      0.94775,
      0.947,
      0.947875,
      0.94825,
      0.947375,
      0.948875,
      0.947375,
      0.949875,
      0.94875,
      0.949,
      0.953875,
      0.9495,
      0.95225,
      0.94975,
      0.9535,
      0.951375,
      0.95375,
      0.954375,
      0.953375,
      0.953,
      0.954625,
      0.953375,
      0.95525,
      0.95725,
      0.955125
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Qwen25_VL/qwen25_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/qwen25vl_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/qwen25vl_model_probe/results/query_token_layer_n_2",
    "MODEL_NAME": "Qwen2.5-VL-7B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_14",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}