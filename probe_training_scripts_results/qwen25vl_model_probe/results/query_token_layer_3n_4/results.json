{
  "model_name": "Qwen2.5-VL-7B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_21",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3584,
  "timestamp": "20251003_182746",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9394,
    "num_hallucination": 606,
    "hallucination_percentage": 6.0600000000000005
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.975,
    "precision": 0.8064516129032258,
    "recall": 0.7731958762886598,
    "f1": 0.7894736842105263,
    "auroc": 0.9879895192433006,
    "confusion_matrix": [
      [
        7425,
        90
      ],
      [
        110,
        375
      ]
    ],
    "num_no_hallucination": 7515,
    "num_hallucination": 485
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.9435,
    "precision": 0.5384615384615384,
    "recall": 0.4628099173553719,
    "f1": 0.49777777777777776,
    "auroc": 0.921489802470982,
    "confusion_matrix": [
      [
        1831,
        48
      ],
      [
        65,
        56
      ]
    ],
    "num_no_hallucination": 1879,
    "num_hallucination": 121
  },
  "training_history": {
    "train_loss": [
      0.42173573076725007,
      0.18413870453834533,
      0.16776226953417062,
      0.15438246037065984,
      0.1476184885278344,
      0.14664330013096333,
      0.13189888605475425,
      0.1333225211724639,
      0.1277693739384413,
      0.12254865942895413,
      0.12563414770364761,
      0.12550123684853315,
      0.11840872689336539,
      0.12196082300692797,
      0.10983501717448235,
      0.11412036897987127,
      0.10884120470285416,
      0.11008496087417007,
      0.10694819428771735,
      0.10119967414438724,
      0.10299957571923733,
      0.09870942705124616,
      0.09613444104418159,
      0.09792870957218111,
      0.09392771371454,
      0.0919927175398916,
      0.09323147309198976,
      0.08984500997886062,
      0.08933914905972778,
      0.08675008803606034,
      0.08589529769867658,
      0.08198437513224781,
      0.08451267406344413,
      0.08464907377213239,
      0.08123585489951074,
      0.08169160916656255,
      0.07782201644778251,
      0.07293945107609033,
      0.0777634846046567,
      0.07407738561369479,
      0.07042945411987603,
      0.07280080694984645,
      0.07160690882615744,
      0.07124607548490167,
      0.07059792125504463,
      0.07294468229822815,
      0.06967216769419611,
      0.07003185907192529,
      0.06723469900991767,
      0.06680836429446936
    ],
    "train_acc": [
      0.83275,
      0.9345,
      0.934125,
      0.938625,
      0.93875,
      0.93875,
      0.944,
      0.94425,
      0.944375,
      0.9485,
      0.945625,
      0.9475,
      0.949875,
      0.948,
      0.948,
      0.949,
      0.952125,
      0.9515,
      0.952,
      0.954,
      0.954125,
      0.9555,
      0.95775,
      0.9575,
      0.961125,
      0.959875,
      0.958625,
      0.959625,
      0.961,
      0.961,
      0.961375,
      0.96475,
      0.961625,
      0.9625,
      0.964375,
      0.963,
      0.96475,
      0.966875,
      0.965,
      0.968125,
      0.969375,
      0.968625,
      0.969875,
      0.968625,
      0.969875,
      0.966375,
      0.969,
      0.97075,
      0.969875,
      0.97
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Qwen25_VL/qwen25_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/qwen25vl_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/qwen25vl_model_probe/results/query_token_layer_3n_4",
    "MODEL_NAME": "Qwen2.5-VL-7B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_21",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}