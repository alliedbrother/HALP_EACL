{
  "model_name": "Qwen2.5-VL-7B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_0",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3584,
  "timestamp": "20251003_182032",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9394,
    "num_hallucination": 606,
    "hallucination_percentage": 6.0600000000000005
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.961375,
    "precision": 0.7291666666666666,
    "recall": 0.5773195876288659,
    "f1": 0.6444188722669736,
    "auroc": 0.9804251291231968,
    "confusion_matrix": [
      [
        7411,
        104
      ],
      [
        205,
        280
      ]
    ],
    "num_no_hallucination": 7515,
    "num_hallucination": 485
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.9125,
    "precision": 0.2,
    "recall": 0.1487603305785124,
    "f1": 0.17061611374407584,
    "auroc": 0.6542626419011344,
    "confusion_matrix": [
      [
        1807,
        72
      ],
      [
        103,
        18
      ]
    ],
    "num_no_hallucination": 1879,
    "num_hallucination": 121
  },
  "training_history": {
    "train_loss": [
      0.437076164573431,
      0.23196325306594373,
      0.20933803874254225,
      0.19413734085857867,
      0.17857100039720536,
      0.16861653344333172,
      0.15611064656078816,
      0.15101854205131532,
      0.14227999080717563,
      0.13393315745890141,
      0.13359523383527994,
      0.12436816439777612,
      0.12467752131074666,
      0.11529231273382902,
      0.11340941272675992,
      0.11754600981995464,
      0.10996580509096385,
      0.10771548251062632,
      0.10454050773009659,
      0.1052691484540701,
      0.09583318961039186,
      0.10126111052930355,
      0.0967633526623249,
      0.09840947122871876,
      0.09812829569354653,
      0.09544022159278392,
      0.08705068044364453,
      0.09330683563277126,
      0.08664463539049029,
      0.09294482862949371,
      0.08991696564853191,
      0.08520143065042794,
      0.08549520616978407,
      0.08891362761333585,
      0.08424451415613293,
      0.08597297343052923,
      0.08403766826726496,
      0.07993004889599979,
      0.07703214982897043,
      0.07721263382025063,
      0.0814294805424288,
      0.0855760626681149,
      0.08015943314507604,
      0.07445127389207483,
      0.07684690431319177,
      0.07923828724306077,
      0.07334137559309602,
      0.07609629223495722,
      0.07441304344590753,
      0.07897134746331722
    ],
    "train_acc": [
      0.83875,
      0.935,
      0.938375,
      0.936625,
      0.9385,
      0.93975,
      0.94125,
      0.941875,
      0.943875,
      0.945,
      0.946375,
      0.948625,
      0.947,
      0.949875,
      0.94925,
      0.946625,
      0.949875,
      0.951125,
      0.95075,
      0.949375,
      0.955,
      0.95125,
      0.954625,
      0.95275,
      0.957125,
      0.954625,
      0.95875,
      0.956125,
      0.95825,
      0.958,
      0.959125,
      0.959,
      0.9575,
      0.957375,
      0.9605,
      0.959125,
      0.958875,
      0.96275,
      0.96325,
      0.962125,
      0.960875,
      0.95825,
      0.961,
      0.961875,
      0.96025,
      0.9615,
      0.962625,
      0.96225,
      0.962625,
      0.961625
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Qwen25_VL/qwen25_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/qwen25vl_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/qwen25vl_model_probe/results/vision_token_layer0",
    "MODEL_NAME": "Qwen2.5-VL-7B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_0",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}