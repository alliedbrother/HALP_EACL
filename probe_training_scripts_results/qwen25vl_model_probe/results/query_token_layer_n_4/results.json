{
  "model_name": "Qwen2.5-VL-7B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_7",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3584,
  "timestamp": "20251003_182601",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9394,
    "num_hallucination": 606,
    "hallucination_percentage": 6.0600000000000005
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.95,
    "precision": 0.9047619047619048,
    "recall": 0.1958762886597938,
    "f1": 0.3220338983050847,
    "auroc": 0.9576656995287776,
    "confusion_matrix": [
      [
        7505,
        10
      ],
      [
        390,
        95
      ]
    ],
    "num_no_hallucination": 7515,
    "num_hallucination": 485
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.9405,
    "precision": 0.5384615384615384,
    "recall": 0.11570247933884298,
    "f1": 0.19047619047619047,
    "auroc": 0.8862547776863903,
    "confusion_matrix": [
      [
        1867,
        12
      ],
      [
        107,
        14
      ]
    ],
    "num_no_hallucination": 1879,
    "num_hallucination": 121
  },
  "training_history": {
    "train_loss": [
      0.42872027760744097,
      0.2218951463252306,
      0.20417624020576478,
      0.1957084817737341,
      0.1856092356443405,
      0.1837769655138254,
      0.18387367197871207,
      0.17963002149760723,
      0.17870707163214683,
      0.17795826306939125,
      0.17353895179927348,
      0.17435612754523755,
      0.1691543917655945,
      0.1696567481160164,
      0.16822164170444012,
      0.16650773198902608,
      0.16632120645046233,
      0.16590319545567037,
      0.1616077579408884,
      0.15889525677263736,
      0.15923848190903664,
      0.1586471447199583,
      0.15830878517031668,
      0.15414151886105537,
      0.1554837911427021,
      0.15325719141960145,
      0.15067476388812065,
      0.14914088147878646,
      0.15148800407350063,
      0.14440211773663758,
      0.14324129638075828,
      0.14235899876058103,
      0.1433255203217268,
      0.1419170907586813,
      0.14012862940132617,
      0.13886116422712802,
      0.13650227265805007,
      0.13554171331226825,
      0.1354865552932024,
      0.13627984245866537,
      0.13352005479484796,
      0.13305437257885933,
      0.13683828374743462,
      0.13179658982157708,
      0.12960039400309326,
      0.13201842544227838,
      0.13136506827175617,
      0.12947212547063827,
      0.12762667877972125,
      0.13480328722298146
    ],
    "train_acc": [
      0.834375,
      0.934875,
      0.936625,
      0.9375,
      0.938375,
      0.937875,
      0.93775,
      0.939625,
      0.93725,
      0.93875,
      0.938,
      0.940125,
      0.938375,
      0.94025,
      0.93925,
      0.93875,
      0.939,
      0.939625,
      0.940625,
      0.939625,
      0.938875,
      0.9405,
      0.941375,
      0.9415,
      0.94075,
      0.9425,
      0.9405,
      0.942375,
      0.941625,
      0.94475,
      0.943125,
      0.9435,
      0.9445,
      0.944625,
      0.946625,
      0.946875,
      0.94575,
      0.946625,
      0.945375,
      0.945375,
      0.946625,
      0.946375,
      0.945125,
      0.948125,
      0.948,
      0.94675,
      0.946875,
      0.947375,
      0.94825,
      0.9465
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Qwen25_VL/qwen25_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/qwen25vl_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/qwen25vl_model_probe/results/query_token_layer_n_4",
    "MODEL_NAME": "Qwen2.5-VL-7B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_7",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}