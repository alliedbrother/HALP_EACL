{
  "model_name": "Gemma3-12B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_36",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3840,
  "timestamp": "20251003_170417",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8942,
    "num_hallucination": 1058,
    "hallucination_percentage": 10.58
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.9595,
    "precision": 0.8407310704960835,
    "recall": 0.7612293144208038,
    "f1": 0.7990074441687345,
    "auroc": 0.9828454844485157,
    "confusion_matrix": [
      [
        7032,
        122
      ],
      [
        202,
        644
      ]
    ],
    "num_no_hallucination": 7154,
    "num_hallucination": 846
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.92,
    "precision": 0.6382978723404256,
    "recall": 0.5660377358490566,
    "f1": 0.6,
    "auroc": 0.9314520809590139,
    "confusion_matrix": [
      [
        1720,
        68
      ],
      [
        92,
        120
      ]
    ],
    "num_no_hallucination": 1788,
    "num_hallucination": 212
  },
  "training_history": {
    "train_loss": [
      0.45018416637182235,
      0.25566582626104356,
      0.2411067058146,
      0.22672610893845557,
      0.21557424876093864,
      0.21200221940875053,
      0.20333748775720598,
      0.20108655060827732,
      0.197764709174633,
      0.1944021986424923,
      0.19425556455552578,
      0.19082215282320977,
      0.18385567344725132,
      0.18578167086839675,
      0.17755322399735451,
      0.1780914204865694,
      0.1744188580363989,
      0.16968873150646688,
      0.16695655521005393,
      0.16653432294726372,
      0.16495496408641339,
      0.16072738893330096,
      0.15865412186086178,
      0.16090603610873222,
      0.14977424113452434,
      0.15552945208549498,
      0.1604828625768423,
      0.14982676592469216,
      0.14721621198952198,
      0.14886933560669421,
      0.14774287834763528,
      0.14194261793792248,
      0.1448752986639738,
      0.14129127710312606,
      0.14032768073678017,
      0.1406591101884842,
      0.1391950748860836,
      0.1343789052516222,
      0.13770887241512536,
      0.13748976908624172,
      0.13075270980596543,
      0.13697770608961582,
      0.13549235297739506,
      0.1296885996311903,
      0.12884216557070613,
      0.12429343675076962,
      0.12983840810507535,
      0.12524855643510818,
      0.1299752555862069,
      0.12168084526062012
    ],
    "train_acc": [
      0.799375,
      0.896,
      0.89475,
      0.89975,
      0.90575,
      0.905875,
      0.9085,
      0.90675,
      0.90925,
      0.91525,
      0.913625,
      0.917,
      0.91825,
      0.91775,
      0.921375,
      0.92075,
      0.9225,
      0.9245,
      0.927625,
      0.927375,
      0.92875,
      0.931,
      0.930125,
      0.93125,
      0.93,
      0.932375,
      0.929,
      0.93525,
      0.934375,
      0.933125,
      0.933625,
      0.9385,
      0.93425,
      0.93975,
      0.942,
      0.9385,
      0.938,
      0.94175,
      0.942375,
      0.94,
      0.941625,
      0.941125,
      0.9395,
      0.94175,
      0.94525,
      0.9475,
      0.941875,
      0.944,
      0.945125,
      0.944625
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Gemma3_12B/gemma_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/gemma3_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/gemma_model_probe/results/query_token_layer_3n_4",
    "MODEL_NAME": "Gemma3-12B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_36",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}