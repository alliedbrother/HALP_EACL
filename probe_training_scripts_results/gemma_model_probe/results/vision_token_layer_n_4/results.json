{
  "model_name": "Gemma3-12B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_12",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3840,
  "timestamp": "20251003_165720",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8942,
    "num_hallucination": 1058,
    "hallucination_percentage": 10.58
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.93475,
    "precision": 0.81640625,
    "recall": 0.4940898345153664,
    "f1": 0.6156111929307806,
    "auroc": 0.9670941581723529,
    "confusion_matrix": [
      [
        7060,
        94
      ],
      [
        428,
        418
      ]
    ],
    "num_no_hallucination": 7154,
    "num_hallucination": 846
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.863,
    "precision": 0.2578125,
    "recall": 0.15566037735849056,
    "f1": 0.19411764705882353,
    "auroc": 0.6697532818369845,
    "confusion_matrix": [
      [
        1693,
        95
      ],
      [
        179,
        33
      ]
    ],
    "num_no_hallucination": 1788,
    "num_hallucination": 212
  },
  "training_history": {
    "train_loss": [
      0.508584143102169,
      0.337364304125309,
      0.31127683827281,
      0.2908573260009289,
      0.27714043429493906,
      0.2619066829681396,
      0.2519777122735977,
      0.241982341080904,
      0.22914889258146287,
      0.2292303493618965,
      0.21796375742554663,
      0.20940375298261643,
      0.20238486075401307,
      0.1969702537059784,
      0.1947426873743534,
      0.19237078735232352,
      0.1847010747641325,
      0.1775722966194153,
      0.17447985950112344,
      0.17958101864159107,
      0.1795903684347868,
      0.1667888884395361,
      0.16520874010026454,
      0.16739977937936784,
      0.16694291245937348,
      0.16209812016785144,
      0.16292139114439488,
      0.16138244479894637,
      0.15535837303102015,
      0.1554966086447239,
      0.15340648888051509,
      0.1557616745084524,
      0.15893483188748359,
      0.15035217387974262,
      0.14700876671820878,
      0.1515025305300951,
      0.14733841245621443,
      0.14636292323470115,
      0.14697935947775842,
      0.1428758903592825,
      0.13750321135669946,
      0.14345220018923283,
      0.1413677681311965,
      0.13682906398177147,
      0.13848539058864118,
      0.13636400870978832,
      0.13635178011655807,
      0.13451074005663394,
      0.1367680840268731,
      0.13359914234280587
    ],
    "train_acc": [
      0.771875,
      0.887125,
      0.894375,
      0.892875,
      0.895125,
      0.900625,
      0.899125,
      0.9005,
      0.904,
      0.903375,
      0.9065,
      0.910375,
      0.91075,
      0.913125,
      0.90825,
      0.911875,
      0.913625,
      0.915,
      0.9185,
      0.91875,
      0.91575,
      0.92175,
      0.921,
      0.922625,
      0.92,
      0.919,
      0.92275,
      0.925125,
      0.921125,
      0.923,
      0.921625,
      0.923125,
      0.925375,
      0.92275,
      0.93175,
      0.925375,
      0.927625,
      0.928375,
      0.92725,
      0.9285,
      0.926625,
      0.925875,
      0.928875,
      0.930375,
      0.925375,
      0.92875,
      0.9315,
      0.928875,
      0.926125,
      0.925625
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Gemma3_12B/gemma_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/gemma3_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/gemma_model_probe/results/vision_token_layer_n_4",
    "MODEL_NAME": "Gemma3-12B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_12",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}