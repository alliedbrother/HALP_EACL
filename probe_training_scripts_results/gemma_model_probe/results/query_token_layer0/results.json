{
  "model_name": "Gemma3-12B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_0",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3840,
  "timestamp": "20251003_170125",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8942,
    "num_hallucination": 1058,
    "hallucination_percentage": 10.58
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.89825,
    "precision": 0.6454545454545455,
    "recall": 0.08392434988179669,
    "f1": 0.14853556485355648,
    "auroc": 0.7541514905777719,
    "confusion_matrix": [
      [
        7115,
        39
      ],
      [
        775,
        71
      ]
    ],
    "num_no_hallucination": 7154,
    "num_hallucination": 846
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.896,
    "precision": 0.5588235294117647,
    "recall": 0.08962264150943396,
    "f1": 0.15447154471544716,
    "auroc": 0.716453505550631,
    "confusion_matrix": [
      [
        1773,
        15
      ],
      [
        193,
        19
      ]
    ],
    "num_no_hallucination": 1788,
    "num_hallucination": 212
  },
  "training_history": {
    "train_loss": [
      0.4980822058320045,
      0.32517799043655393,
      0.31208286514878275,
      0.29847835287451746,
      0.2952589415311813,
      0.2896155843734741,
      0.28957032185792925,
      0.28396505734324456,
      0.28234943249821665,
      0.27930691263079643,
      0.277495005518198,
      0.2773333096206188,
      0.2777945829331875,
      0.2726251817345619,
      0.27463865756988526,
      0.2748337941765785,
      0.273800517141819,
      0.26778459158539775,
      0.26763377740979194,
      0.26630174031853676,
      0.2645742853879929,
      0.26650253343582153,
      0.26432557252049443,
      0.26615478122234343,
      0.26215752613544463,
      0.2625121736824512,
      0.264464969843626,
      0.26248043859004977,
      0.2632344841659069,
      0.2603739007413387,
      0.25833919844031333,
      0.25649033346772193,
      0.25983273196220397,
      0.2578618015944958,
      0.2599899507164955,
      0.259358257830143,
      0.25612660381197927,
      0.25478285291790964,
      0.2544616337418556,
      0.258668678432703,
      0.2562746243476868,
      0.25668080338835714,
      0.25460614570975304,
      0.2524623277187347,
      0.2603604057729244,
      0.2569626301229,
      0.2560028046965599,
      0.2523912236094475,
      0.25437821981310843,
      0.25358846431970594
    ],
    "train_acc": [
      0.781625,
      0.887375,
      0.886625,
      0.891375,
      0.891,
      0.893375,
      0.893625,
      0.89525,
      0.895375,
      0.89325,
      0.8935,
      0.892375,
      0.893875,
      0.8945,
      0.89525,
      0.89375,
      0.894375,
      0.896125,
      0.895625,
      0.895125,
      0.896625,
      0.8965,
      0.896375,
      0.89625,
      0.896,
      0.89675,
      0.894875,
      0.8955,
      0.896375,
      0.896625,
      0.898125,
      0.8965,
      0.89575,
      0.896625,
      0.89475,
      0.896625,
      0.896375,
      0.897625,
      0.895625,
      0.8975,
      0.89775,
      0.897875,
      0.896875,
      0.8955,
      0.895875,
      0.896125,
      0.8965,
      0.897625,
      0.89825,
      0.89425
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Gemma3_12B/gemma_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/gemma3_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/gemma_model_probe/results/query_token_layer0",
    "MODEL_NAME": "Gemma3-12B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_0",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}