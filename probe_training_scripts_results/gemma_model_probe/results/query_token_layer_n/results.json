{
  "model_name": "Gemma3-12B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_47",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3840,
  "timestamp": "20251003_170516",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8942,
    "num_hallucination": 1058,
    "hallucination_percentage": 10.58
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.97775,
    "precision": 0.93717277486911,
    "recall": 0.8463356973995272,
    "f1": 0.8894409937888199,
    "auroc": 0.9969664344898554,
    "confusion_matrix": [
      [
        7106,
        48
      ],
      [
        130,
        716
      ]
    ],
    "num_no_hallucination": 7154,
    "num_hallucination": 846
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.9195,
    "precision": 0.6545454545454545,
    "recall": 0.5094339622641509,
    "f1": 0.5729442970822282,
    "auroc": 0.9348935249672871,
    "confusion_matrix": [
      [
        1731,
        57
      ],
      [
        104,
        108
      ]
    ],
    "num_no_hallucination": 1788,
    "num_hallucination": 212
  },
  "training_history": {
    "train_loss": [
      0.45870783084630967,
      0.2548106491565704,
      0.22702895379066468,
      0.21484842750430108,
      0.20147632119059564,
      0.20059743301570415,
      0.184949373498559,
      0.18231144511699676,
      0.1772268090546131,
      0.16877962712943553,
      0.1644901588410139,
      0.15956723652780055,
      0.16023177704960107,
      0.1515463697016239,
      0.15192580418288706,
      0.1496058573871851,
      0.14734548304229975,
      0.14384446129202844,
      0.13539261843264103,
      0.13896129439026117,
      0.1312484973371029,
      0.12967570742219686,
      0.12793689232319594,
      0.12672227315604687,
      0.124617569796741,
      0.12575738161057234,
      0.12000965116918087,
      0.11774855955690146,
      0.11727239231020212,
      0.1126656627729535,
      0.1076958849877119,
      0.11239509004727007,
      0.107392046302557,
      0.10538560751453042,
      0.10547119560837746,
      0.10408249137550593,
      0.10463414616510272,
      0.10419629646465182,
      0.101392432667315,
      0.10045692541450262,
      0.09356026569753885,
      0.09998960402607918,
      0.09404290341585875,
      0.09414043205231429,
      0.0943693589773029,
      0.08800830152630806,
      0.0846539851743728,
      0.08945965620875358,
      0.08121692634373903,
      0.09172982435300946
    ],
    "train_acc": [
      0.80325,
      0.898375,
      0.900125,
      0.9025,
      0.90975,
      0.9125,
      0.919875,
      0.92025,
      0.9215,
      0.92425,
      0.927875,
      0.93025,
      0.92875,
      0.9325,
      0.93425,
      0.933125,
      0.93425,
      0.93525,
      0.93675,
      0.939125,
      0.942375,
      0.94525,
      0.94375,
      0.943875,
      0.946625,
      0.94525,
      0.944625,
      0.949375,
      0.950375,
      0.950375,
      0.9525,
      0.950125,
      0.9535,
      0.951875,
      0.955875,
      0.953375,
      0.954625,
      0.954125,
      0.9555,
      0.955,
      0.957875,
      0.955875,
      0.956875,
      0.96025,
      0.958125,
      0.95975,
      0.962625,
      0.961625,
      0.9635,
      0.96
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Gemma3_12B/gemma_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/gemma3_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/gemma_model_probe/results/query_token_layer_n",
    "MODEL_NAME": "Gemma3-12B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_47",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}