{
  "model_name": "Gemma3-12B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_12",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3840,
  "timestamp": "20251003_170222",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8942,
    "num_hallucination": 1058,
    "hallucination_percentage": 10.58
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.89825,
    "precision": 0.75,
    "recall": 0.05673758865248227,
    "f1": 0.1054945054945055,
    "auroc": 0.9144779061921086,
    "confusion_matrix": [
      [
        7138,
        16
      ],
      [
        798,
        48
      ]
    ],
    "num_no_hallucination": 7154,
    "num_hallucination": 846
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.8955,
    "precision": 0.6363636363636364,
    "recall": 0.0330188679245283,
    "f1": 0.06278026905829596,
    "auroc": 0.8119222489552995,
    "confusion_matrix": [
      [
        1784,
        4
      ],
      [
        205,
        7
      ]
    ],
    "num_no_hallucination": 1788,
    "num_hallucination": 212
  },
  "training_history": {
    "train_loss": [
      0.4574358817338943,
      0.3007451773583889,
      0.27933039447665214,
      0.2704384283721447,
      0.263987348228693,
      0.26078695052862166,
      0.2590512317419052,
      0.2542587583363056,
      0.248271127730608,
      0.24852455404400825,
      0.24671971222758293,
      0.24443072625994683,
      0.23959814542531968,
      0.2411816222369671,
      0.23795549473166466,
      0.2356924524307251,
      0.23781919926404954,
      0.23233313485980034,
      0.2333713031411171,
      0.2341998048722744,
      0.23319521582126618,
      0.23155363380908967,
      0.22892647475004196,
      0.2290612280368805,
      0.2277986416220665,
      0.22216825807094573,
      0.2282955267727375,
      0.2254389238357544,
      0.22386361780762673,
      0.21871374547481537,
      0.2174057847261429,
      0.21765811920166014,
      0.2178366551399231,
      0.2196447225213051,
      0.21384762182831765,
      0.21347937929630278,
      0.21626214334368707,
      0.21195269057154656,
      0.21215327632427217,
      0.210325859606266,
      0.2099412712752819,
      0.20748763254284858,
      0.20714305789768697,
      0.2022887222468853,
      0.2055451540350914,
      0.20571100094914435,
      0.20171479220688343,
      0.20128482058644295,
      0.20370652934908867,
      0.2024645667374134
    ],
    "train_acc": [
      0.812375,
      0.884375,
      0.88925,
      0.891375,
      0.891,
      0.8925,
      0.8935,
      0.896,
      0.898,
      0.898375,
      0.894625,
      0.8985,
      0.89925,
      0.898375,
      0.899,
      0.898875,
      0.89675,
      0.902,
      0.898125,
      0.897125,
      0.898,
      0.896375,
      0.8985,
      0.900625,
      0.899,
      0.902625,
      0.898625,
      0.900625,
      0.901625,
      0.901875,
      0.905375,
      0.903875,
      0.902375,
      0.905125,
      0.89975,
      0.902125,
      0.900625,
      0.904625,
      0.904,
      0.90475,
      0.902375,
      0.90875,
      0.908375,
      0.907125,
      0.9065,
      0.906875,
      0.906,
      0.9105,
      0.907125,
      0.9055
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Gemma3_12B/gemma_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/gemma3_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/gemma_model_probe/results/query_token_layer_n_4",
    "MODEL_NAME": "Gemma3-12B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_12",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}