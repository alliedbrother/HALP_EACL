{
  "model_name": "Gemma3-12B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_24",
  "target_column": "is_hallucinating_manual",
  "input_dim": 3840,
  "timestamp": "20251003_170320",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 8942,
    "num_hallucination": 1058,
    "hallucination_percentage": 10.58
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.949,
    "precision": 0.875,
    "recall": 0.6040189125295509,
    "f1": 0.7146853146853147,
    "auroc": 0.9837320092712107,
    "confusion_matrix": [
      [
        7081,
        73
      ],
      [
        335,
        511
      ]
    ],
    "num_no_hallucination": 7154,
    "num_hallucination": 846
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.9105,
    "precision": 0.632,
    "recall": 0.37264150943396224,
    "f1": 0.4688427299703264,
    "auroc": 0.9247287999662319,
    "confusion_matrix": [
      [
        1742,
        46
      ],
      [
        133,
        79
      ]
    ],
    "num_no_hallucination": 1788,
    "num_hallucination": 212
  },
  "training_history": {
    "train_loss": [
      0.4590389875173569,
      0.2650955787599087,
      0.24584102988243103,
      0.2230735996812582,
      0.21666291043162345,
      0.2064907712340355,
      0.2007499112188816,
      0.19562234763801098,
      0.1976234183460474,
      0.19031161677837372,
      0.19037566916644574,
      0.18046106652915478,
      0.1796806176751852,
      0.16963621032238008,
      0.17135631880164146,
      0.16647072957456113,
      0.1637034883350134,
      0.16729581613838673,
      0.1603205190449953,
      0.15886389289796352,
      0.15220115292072295,
      0.15440643939375878,
      0.1500772869884968,
      0.14798154611885547,
      0.14148001691699028,
      0.1468647106960416,
      0.14146884089708328,
      0.13975637499988078,
      0.1363093035966158,
      0.13422894710302352,
      0.13677981116622687,
      0.13628368699550628,
      0.1323402976691723,
      0.13223374632745982,
      0.1282326619103551,
      0.1294070880487561,
      0.134770857848227,
      0.12324519103765488,
      0.12376436773315072,
      0.12681737638264895,
      0.12173183389753103,
      0.12556379484385252,
      0.11928142503648996,
      0.11483017329126596,
      0.11519780927151442,
      0.11119822588562965,
      0.1087341198399663,
      0.11192688065953553,
      0.10863013156503439,
      0.10792648138850927
    ],
    "train_acc": [
      0.805,
      0.891125,
      0.896,
      0.90025,
      0.90525,
      0.907875,
      0.9135,
      0.91225,
      0.91275,
      0.912875,
      0.916375,
      0.919375,
      0.92125,
      0.925,
      0.921375,
      0.9255,
      0.924,
      0.9235,
      0.92675,
      0.928375,
      0.933875,
      0.929625,
      0.934375,
      0.9345,
      0.937375,
      0.93275,
      0.93975,
      0.938125,
      0.94025,
      0.9405,
      0.93975,
      0.94075,
      0.941375,
      0.9405,
      0.94325,
      0.94125,
      0.941375,
      0.944,
      0.945125,
      0.9415,
      0.946125,
      0.94375,
      0.947625,
      0.950125,
      0.950125,
      0.9515,
      0.952875,
      0.953375,
      0.951375,
      0.95425
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Gemma3_12B/gemma_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/gemma3_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/gemma_model_probe/results/query_token_layer_n_2",
    "MODEL_NAME": "Gemma3-12B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_24",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}