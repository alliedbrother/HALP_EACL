{
  "model_name": "SmolVLM2-2.2B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_0",
  "target_column": "is_hallucinating_manual",
  "input_dim": 2048,
  "timestamp": "20251004_120357",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9009,
    "num_hallucination": 991,
    "hallucination_percentage": 9.91
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.900875,
    "precision": 0.0,
    "recall": 0.0,
    "f1": 0.0,
    "auroc": 0.5,
    "confusion_matrix": [
      [
        7207,
        0
      ],
      [
        793,
        0
      ]
    ],
    "num_no_hallucination": 7207,
    "num_hallucination": 793
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.901,
    "precision": 0.0,
    "recall": 0.0,
    "f1": 0.0,
    "auroc": 0.5039686543571116,
    "confusion_matrix": [
      [
        1802,
        0
      ],
      [
        198,
        0
      ]
    ],
    "num_no_hallucination": 1802,
    "num_hallucination": 198
  },
  "training_history": {
    "train_loss": [
      0.5183533095121383,
      0.3605999675691128,
      0.34836095675826073,
      0.3406284680068493,
      0.3384152123630047,
      0.3329515631794929,
      0.3326054134964943,
      0.33204235225915907,
      0.3316639417409897,
      0.330933909535408,
      0.33027898508310316,
      0.3307328640818596,
      0.32936423242092133,
      0.32707245904207227,
      0.3285044148564339,
      0.3287416220009327,
      0.3293430458307266,
      0.32932397711277006,
      0.32803979128599164,
      0.3283376032412052,
      0.3281516858935356,
      0.32805416351556776,
      0.3270842002630234,
      0.32641133150458335,
      0.3279831975698471,
      0.32734727090597154,
      0.3276683086156845,
      0.3266976555287838,
      0.32710275104641917,
      0.32651776641607283,
      0.32578634285926816,
      0.32770406794548035,
      0.32664947295188906,
      0.32723693856596947,
      0.32667869207262995,
      0.3267577883601189,
      0.3269591656625271,
      0.32715927389264104,
      0.32427389216423036,
      0.3268200958073139,
      0.32636360412836074,
      0.32617099419236184,
      0.3275934959053993,
      0.3250502935051918,
      0.32631726974248887,
      0.3250619103610516,
      0.3250032688677311,
      0.3267426809668541,
      0.32624002191424367,
      0.3249285699725151
    ],
    "train_acc": [
      0.76625,
      0.8985,
      0.899375,
      0.900875,
      0.90075,
      0.90075,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875,
      0.900875
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Smol_VL/smolvlm_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/smolvlm_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/smolvlm_model_probe/results/query_token_layer0",
    "MODEL_NAME": "SmolVLM2-2.2B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_0",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}