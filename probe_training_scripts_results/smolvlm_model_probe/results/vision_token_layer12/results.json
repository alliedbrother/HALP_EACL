{
  "model_name": "SmolVLM2-2.2B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_12",
  "target_column": "is_hallucinating_manual",
  "input_dim": 2048,
  "timestamp": "20251004_120122",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9009,
    "num_hallucination": 991,
    "hallucination_percentage": 9.91
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.92725,
    "precision": 0.7604938271604939,
    "recall": 0.3883984867591425,
    "f1": 0.5141903171953256,
    "auroc": 0.9559996752491754,
    "confusion_matrix": [
      [
        7110,
        97
      ],
      [
        485,
        308
      ]
    ],
    "num_no_hallucination": 7207,
    "num_hallucination": 793
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.8745,
    "precision": 0.26126126126126126,
    "recall": 0.14646464646464646,
    "f1": 0.18770226537216828,
    "auroc": 0.6844863731656184,
    "confusion_matrix": [
      [
        1720,
        82
      ],
      [
        169,
        29
      ]
    ],
    "num_no_hallucination": 1802,
    "num_hallucination": 198
  },
  "training_history": {
    "train_loss": [
      0.47282945770025253,
      0.3227208493053913,
      0.300054768383503,
      0.29139637464284895,
      0.27664088243246077,
      0.2697429712712765,
      0.2646169999241829,
      0.25873237833380697,
      0.2491005427837372,
      0.24388258254528045,
      0.23924596485495567,
      0.24200555807352067,
      0.22684494438767433,
      0.22556844958662986,
      0.22676742824912072,
      0.219419388204813,
      0.21143909534811975,
      0.2077411254644394,
      0.20548334208130836,
      0.2033355932533741,
      0.2046835440993309,
      0.20171094396710396,
      0.20049239966273308,
      0.19596472722291947,
      0.1951653892993927,
      0.19173954182863234,
      0.1901508272588253,
      0.1914820903837681,
      0.18487366463243962,
      0.18644295255839824,
      0.18074291314184665,
      0.1818713858127594,
      0.1813504259288311,
      0.1798642206788063,
      0.1786772622168064,
      0.17280529387295246,
      0.17378957962989808,
      0.1787236333489418,
      0.17487666928768159,
      0.1698521011173725,
      0.1739504837244749,
      0.1714221583455801,
      0.16545813232660295,
      0.1704303699582815,
      0.17022651258111,
      0.16670064325630665,
      0.1667846514582634,
      0.16305192570388316,
      0.16658342969417572,
      0.160787260055542
    ],
    "train_acc": [
      0.80375,
      0.89575,
      0.900125,
      0.900125,
      0.899875,
      0.90125,
      0.90425,
      0.9015,
      0.90425,
      0.90225,
      0.90625,
      0.905,
      0.906375,
      0.906,
      0.9055,
      0.909625,
      0.90925,
      0.911875,
      0.911,
      0.913125,
      0.91225,
      0.911875,
      0.911625,
      0.913,
      0.91125,
      0.91225,
      0.916625,
      0.91425,
      0.9155,
      0.91325,
      0.914375,
      0.9145,
      0.916125,
      0.914875,
      0.914625,
      0.917625,
      0.91825,
      0.914,
      0.91425,
      0.91775,
      0.916125,
      0.9195,
      0.918375,
      0.915,
      0.919375,
      0.92125,
      0.9205,
      0.919875,
      0.9195,
      0.92325
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Smol_VL/smolvlm_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/smolvlm_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/smolvlm_model_probe/results/vision_token_layer12",
    "MODEL_NAME": "SmolVLM2-2.2B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_12",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}