{
  "model_name": "SmolVLM2-2.2B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_18",
  "target_column": "is_hallucinating_manual",
  "input_dim": 2048,
  "timestamp": "20251004_120635",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9009,
    "num_hallucination": 991,
    "hallucination_percentage": 9.91
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.969625,
    "precision": 0.8676470588235294,
    "recall": 0.8184110970996217,
    "f1": 0.8423101881894873,
    "auroc": 0.9924455189372948,
    "confusion_matrix": [
      [
        7108,
        99
      ],
      [
        144,
        649
      ]
    ],
    "num_no_hallucination": 7207,
    "num_hallucination": 793
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.903,
    "precision": 0.5117647058823529,
    "recall": 0.4393939393939394,
    "f1": 0.47282608695652173,
    "auroc": 0.9272147109272525,
    "confusion_matrix": [
      [
        1719,
        83
      ],
      [
        111,
        87
      ]
    ],
    "num_no_hallucination": 1802,
    "num_hallucination": 198
  },
  "training_history": {
    "train_loss": [
      0.41649000164866445,
      0.22765724247694016,
      0.20447521099448204,
      0.18456021428108216,
      0.17912842033058404,
      0.17715352866053583,
      0.1671307952553034,
      0.1590999791622162,
      0.16263348644971848,
      0.1554970943182707,
      0.15781818756461144,
      0.15064327958226204,
      0.14523405195772648,
      0.14409818740189076,
      0.14135295659303665,
      0.13922474670410157,
      0.13812764873355626,
      0.13734038014709948,
      0.13311543802171946,
      0.12703937500715257,
      0.13065223411470653,
      0.12513237272202968,
      0.12337277212738991,
      0.11715516033768654,
      0.1281905906945467,
      0.12063714351505041,
      0.11821233652532101,
      0.11577532494440675,
      0.11208042062446474,
      0.11237774109095335,
      0.11208277617394924,
      0.11351457431539894,
      0.10988891114667058,
      0.1054986384715885,
      0.10805922517552972,
      0.10682567224651575,
      0.10622915714234114,
      0.1063766301125288,
      0.11114305862411857,
      0.09959639696776867,
      0.09847567771375179,
      0.0964378374889493,
      0.09502013332024217,
      0.09731631015241146,
      0.09185263166576624,
      0.09232451113685966,
      0.09120340083166957,
      0.09511910748668015,
      0.0962636453397572,
      0.0923896794244647
    ],
    "train_acc": [
      0.83675,
      0.90925,
      0.914125,
      0.9215,
      0.925,
      0.92425,
      0.926375,
      0.9295,
      0.9255,
      0.931125,
      0.930625,
      0.932875,
      0.934125,
      0.9345,
      0.936,
      0.9375,
      0.934625,
      0.93825,
      0.938,
      0.9425,
      0.937375,
      0.941875,
      0.943875,
      0.945375,
      0.9405,
      0.9445,
      0.948,
      0.94575,
      0.94825,
      0.947,
      0.94625,
      0.94625,
      0.952,
      0.949375,
      0.9495,
      0.9525,
      0.95225,
      0.950125,
      0.9485,
      0.953875,
      0.954625,
      0.956625,
      0.957125,
      0.956,
      0.956875,
      0.95825,
      0.959,
      0.958375,
      0.956875,
      0.957
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Smol_VL/smolvlm_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/smolvlm_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/smolvlm_model_probe/results/query_token_layer18",
    "MODEL_NAME": "SmolVLM2-2.2B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_18",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}