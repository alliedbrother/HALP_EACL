{
  "model_name": "SmolVLM2-2.2B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_0",
  "target_column": "is_hallucinating_manual",
  "input_dim": 2048,
  "timestamp": "20251004_115937",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9009,
    "num_hallucination": 991,
    "hallucination_percentage": 9.91
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.91575,
    "precision": 0.6355353075170843,
    "recall": 0.35182849936948296,
    "f1": 0.45292207792207795,
    "auroc": 0.9404839872122364,
    "confusion_matrix": [
      [
        7047,
        160
      ],
      [
        514,
        279
      ]
    ],
    "num_no_hallucination": 7207,
    "num_hallucination": 793
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.885,
    "precision": 0.3333333333333333,
    "recall": 0.16161616161616163,
    "f1": 0.21768707482993196,
    "auroc": 0.6829000325115753,
    "confusion_matrix": [
      [
        1738,
        64
      ],
      [
        166,
        32
      ]
    ],
    "num_no_hallucination": 1802,
    "num_hallucination": 198
  },
  "training_history": {
    "train_loss": [
      0.48496543961763383,
      0.32924250268936156,
      0.31286807358264923,
      0.2999658592939377,
      0.2933097648024559,
      0.28189310544729235,
      0.277318689763546,
      0.2757629311084747,
      0.2668266940712929,
      0.2632775972485542,
      0.2610923279821873,
      0.25520784765481946,
      0.2534656274318695,
      0.249433836966753,
      0.24602254816889763,
      0.24298184803128242,
      0.24230956959724426,
      0.23839768454432486,
      0.23217979577183723,
      0.23195353776216507,
      0.22757095298171043,
      0.22702025160193443,
      0.228867685765028,
      0.22685902750492096,
      0.22061298596858978,
      0.2206427915096283,
      0.22264248630404473,
      0.21881077456474304,
      0.21940960323810577,
      0.21605429524183273,
      0.21600345994532108,
      0.21516148248314856,
      0.2108445585668087,
      0.20951909998059273,
      0.21444791689515114,
      0.20867881491780282,
      0.20887834942340852,
      0.20981639191508294,
      0.2093564246892929,
      0.20438510584831238,
      0.19833130756020545,
      0.2059259424507618,
      0.20638259449601173,
      0.2067586929500103,
      0.20269626839458943,
      0.202674069583416,
      0.19905235004425048,
      0.19818606665730476,
      0.19648100170493127,
      0.19651150739192963
    ],
    "train_acc": [
      0.79825,
      0.895375,
      0.898375,
      0.900375,
      0.8985,
      0.901,
      0.90175,
      0.901125,
      0.902125,
      0.903,
      0.90225,
      0.90325,
      0.90375,
      0.90275,
      0.90625,
      0.904375,
      0.90525,
      0.90275,
      0.90675,
      0.90475,
      0.906375,
      0.905,
      0.9075,
      0.903625,
      0.90775,
      0.90875,
      0.907625,
      0.906625,
      0.9075,
      0.908875,
      0.906875,
      0.90825,
      0.90825,
      0.90775,
      0.90975,
      0.90825,
      0.90925,
      0.911125,
      0.90875,
      0.908625,
      0.912375,
      0.91025,
      0.913,
      0.9115,
      0.912125,
      0.91175,
      0.913,
      0.911875,
      0.9115,
      0.913625
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Smol_VL/smolvlm_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/smolvlm_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/smolvlm_model_probe/results/vision_token_layer0",
    "MODEL_NAME": "SmolVLM2-2.2B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_0",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}