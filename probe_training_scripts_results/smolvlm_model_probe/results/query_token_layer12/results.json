{
  "model_name": "SmolVLM2-2.2B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_12",
  "target_column": "is_hallucinating_manual",
  "input_dim": 2048,
  "timestamp": "20251004_120544",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9009,
    "num_hallucination": 991,
    "hallucination_percentage": 9.91
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.94775,
    "precision": 0.8099173553719008,
    "recall": 0.617906683480454,
    "f1": 0.7010014306151645,
    "auroc": 0.9804384871020906,
    "confusion_matrix": [
      [
        7092,
        115
      ],
      [
        303,
        490
      ]
    ],
    "num_no_hallucination": 7207,
    "num_hallucination": 793
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.9065,
    "precision": 0.5390070921985816,
    "recall": 0.3838383838383838,
    "f1": 0.44837758112094395,
    "auroc": 0.9054711936232469,
    "confusion_matrix": [
      [
        1737,
        65
      ],
      [
        122,
        76
      ]
    ],
    "num_no_hallucination": 1802,
    "num_hallucination": 198
  },
  "training_history": {
    "train_loss": [
      0.4434479811191559,
      0.2522867596447468,
      0.2388094621896744,
      0.22796311795711519,
      0.21541465809941293,
      0.21566745176911353,
      0.2077174015045166,
      0.20675191029906273,
      0.20054076611995697,
      0.2018617841899395,
      0.19967451944947243,
      0.19514699041843414,
      0.18995777052640914,
      0.18804770709574223,
      0.18495424063503743,
      0.18528025811910628,
      0.18644936779141427,
      0.17868015405535698,
      0.1781214480549097,
      0.17539920590817928,
      0.17778107824921607,
      0.17311017210781574,
      0.17618660320341586,
      0.16971581035852432,
      0.16605458718538285,
      0.16504578633606434,
      0.16451420897245408,
      0.16151124662160873,
      0.1669719260632992,
      0.1588608570098877,
      0.15867883056402207,
      0.15982695518434048,
      0.15749216885119677,
      0.16012412655353547,
      0.1534124093055725,
      0.1532998111695051,
      0.15104606008529664,
      0.13707732926309107,
      0.14817439983785152,
      0.14281768039613962,
      0.1487390128970146,
      0.14073918958753348,
      0.14380264396220446,
      0.13837963243573903,
      0.14048875205218792,
      0.1417470539584756,
      0.14184791003912686,
      0.1442597368955612,
      0.13890797635912897,
      0.1359912553280592
    ],
    "train_acc": [
      0.804875,
      0.900125,
      0.90575,
      0.905125,
      0.908625,
      0.90975,
      0.91075,
      0.911875,
      0.914,
      0.9135,
      0.9155,
      0.9185,
      0.921625,
      0.91925,
      0.921625,
      0.919625,
      0.91825,
      0.924375,
      0.926625,
      0.925,
      0.922375,
      0.92375,
      0.9215,
      0.925,
      0.92475,
      0.92675,
      0.926875,
      0.928125,
      0.928,
      0.928875,
      0.92975,
      0.9295,
      0.9275,
      0.9295,
      0.93075,
      0.930875,
      0.9325,
      0.936375,
      0.9315,
      0.934875,
      0.93525,
      0.939,
      0.934,
      0.939,
      0.937,
      0.937125,
      0.93475,
      0.93575,
      0.938,
      0.937875
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Smol_VL/smolvlm_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/smolvlm_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/smolvlm_model_probe/results/query_token_layer12",
    "MODEL_NAME": "SmolVLM2-2.2B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_12",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}