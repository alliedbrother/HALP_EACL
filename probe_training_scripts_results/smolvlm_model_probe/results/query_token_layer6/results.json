{
  "model_name": "SmolVLM2-2.2B",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_6",
  "target_column": "is_hallucinating_manual",
  "input_dim": 2048,
  "timestamp": "20251004_120450",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9009,
    "num_hallucination": 991,
    "hallucination_percentage": 9.91
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.938375,
    "precision": 0.7199413489736071,
    "recall": 0.6191677175283733,
    "f1": 0.6657627118644068,
    "auroc": 0.9654334592384348,
    "confusion_matrix": [
      [
        7016,
        191
      ],
      [
        302,
        491
      ]
    ],
    "num_no_hallucination": 7207,
    "num_hallucination": 793
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.899,
    "precision": 0.48717948717948717,
    "recall": 0.3838383838383838,
    "f1": 0.4293785310734463,
    "auroc": 0.8970770412224351,
    "confusion_matrix": [
      [
        1722,
        80
      ],
      [
        122,
        76
      ]
    ],
    "num_no_hallucination": 1802,
    "num_hallucination": 198
  },
  "training_history": {
    "train_loss": [
      0.449551972925663,
      0.27123088428378106,
      0.25437940353155136,
      0.23769789257645607,
      0.2324103987812996,
      0.22813842836022377,
      0.2226776792705059,
      0.2224820965528488,
      0.2156914387047291,
      0.21288893219828606,
      0.21493440061807634,
      0.20761996921896936,
      0.20338474473357201,
      0.20766809067130088,
      0.2045070915967226,
      0.19960444474220276,
      0.202302852794528,
      0.19973294883966447,
      0.19761682087183,
      0.19527991783618928,
      0.19703264601528644,
      0.19530421504378317,
      0.19235500371456146,
      0.18972466914355754,
      0.1904141066223383,
      0.18978291434049607,
      0.18573551711440087,
      0.18304998575150966,
      0.18610077926516533,
      0.18858790071308612,
      0.18418855805695056,
      0.1842042285501957,
      0.18356377781927585,
      0.17765701426565647,
      0.1783103093057871,
      0.17981584984064103,
      0.1768039713203907,
      0.1759859978556633,
      0.18037775491178035,
      0.17330153660476208,
      0.17592030328512193,
      0.1761827556937933,
      0.1719241402000189,
      0.17242196115851402,
      0.16984641379117965,
      0.16834473705291747,
      0.16807058399915695,
      0.16608919802308084,
      0.1702460576891899,
      0.1676700272411108
    ],
    "train_acc": [
      0.816125,
      0.894125,
      0.896625,
      0.9015,
      0.90075,
      0.90225,
      0.90725,
      0.90275,
      0.905,
      0.90875,
      0.908,
      0.907625,
      0.911875,
      0.9085,
      0.9125,
      0.914,
      0.91125,
      0.91075,
      0.91475,
      0.9135,
      0.9095,
      0.915375,
      0.913375,
      0.915125,
      0.91225,
      0.917125,
      0.916375,
      0.920125,
      0.921375,
      0.91775,
      0.915875,
      0.917125,
      0.92,
      0.92125,
      0.9215,
      0.919125,
      0.9215,
      0.92375,
      0.920375,
      0.922625,
      0.922125,
      0.92125,
      0.923875,
      0.925375,
      0.92225,
      0.92575,
      0.927,
      0.925375,
      0.922875,
      0.92325
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Smol_VL/smolvlm_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/smolvlm_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/smolvlm_model_probe/results/query_token_layer6",
    "MODEL_NAME": "SmolVLM2-2.2B",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_6",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}