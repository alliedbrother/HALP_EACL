{
  "model_name": "SmolVLM2-2.2B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_6",
  "target_column": "is_hallucinating_manual",
  "input_dim": 2048,
  "timestamp": "20251004_120030",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9009,
    "num_hallucination": 991,
    "hallucination_percentage": 9.91
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.9205,
    "precision": 0.8369098712446352,
    "recall": 0.2459016393442623,
    "f1": 0.38011695906432746,
    "auroc": 0.9432230224538249,
    "confusion_matrix": [
      [
        7169,
        38
      ],
      [
        598,
        195
      ]
    ],
    "num_no_hallucination": 7207,
    "num_hallucination": 793
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.8895,
    "precision": 0.3424657534246575,
    "recall": 0.12626262626262627,
    "f1": 0.18450184501845018,
    "auroc": 0.686809829706611,
    "confusion_matrix": [
      [
        1754,
        48
      ],
      [
        173,
        25
      ]
    ],
    "num_no_hallucination": 1802,
    "num_hallucination": 198
  },
  "training_history": {
    "train_loss": [
      0.47891804629564283,
      0.32160501819849013,
      0.30893027967214587,
      0.2927369990646839,
      0.28317352330684664,
      0.27533266419172286,
      0.268787032186985,
      0.26523081767559054,
      0.2569727411270142,
      0.25285085159540177,
      0.24797120228409766,
      0.24152101877331733,
      0.23888005632162093,
      0.2359985283613205,
      0.2298357410132885,
      0.2248590211570263,
      0.22882635045051575,
      0.22661768215894698,
      0.22643704131245612,
      0.2215337266921997,
      0.21294015142321587,
      0.21292290657758714,
      0.2078351997733116,
      0.20746894833445548,
      0.2117860798239708,
      0.20788239490985871,
      0.20355295690894126,
      0.2065727434158325,
      0.20366286119818688,
      0.20042203176021575,
      0.2010644516199827,
      0.19503506895899772,
      0.19368137331306934,
      0.193019644215703,
      0.1944149915277958,
      0.18784151217341424,
      0.18653898525238038,
      0.19268139937520026,
      0.18773512640595436,
      0.1902833311855793,
      0.18239757433533668,
      0.1796831657886505,
      0.18653074473142625,
      0.1775669310539961,
      0.18665188732743263,
      0.18359917211532592,
      0.18483100458979607,
      0.17911338996887208,
      0.18097147141397,
      0.17805130377411843
    ],
    "train_acc": [
      0.811375,
      0.896875,
      0.897375,
      0.89975,
      0.901125,
      0.901875,
      0.901125,
      0.903375,
      0.901875,
      0.903875,
      0.903125,
      0.90475,
      0.9035,
      0.90675,
      0.906,
      0.907375,
      0.90425,
      0.90525,
      0.905125,
      0.906125,
      0.91075,
      0.9085,
      0.907,
      0.910875,
      0.909875,
      0.906375,
      0.905625,
      0.906,
      0.909375,
      0.90775,
      0.910875,
      0.91025,
      0.911,
      0.91175,
      0.910875,
      0.912625,
      0.913625,
      0.90975,
      0.912875,
      0.912,
      0.91325,
      0.916,
      0.910375,
      0.91675,
      0.91525,
      0.915625,
      0.914,
      0.915,
      0.913,
      0.916375
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Smol_VL/smolvlm_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/smolvlm_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/smolvlm_model_probe/results/vision_token_layer6",
    "MODEL_NAME": "SmolVLM2-2.2B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_6",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}