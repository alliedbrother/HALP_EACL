{
  "model_name": "SmolVLM2-2.2B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_18",
  "target_column": "is_hallucinating_manual",
  "input_dim": 2048,
  "timestamp": "20251004_120214",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9009,
    "num_hallucination": 991,
    "hallucination_percentage": 9.91
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.924375,
    "precision": 0.719626168224299,
    "recall": 0.3883984867591425,
    "f1": 0.5045045045045045,
    "auroc": 0.9504885347736219,
    "confusion_matrix": [
      [
        7087,
        120
      ],
      [
        485,
        308
      ]
    ],
    "num_no_hallucination": 7207,
    "num_hallucination": 793
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.872,
    "precision": 0.2542372881355932,
    "recall": 0.15151515151515152,
    "f1": 0.189873417721519,
    "auroc": 0.6800945077859618,
    "confusion_matrix": [
      [
        1714,
        88
      ],
      [
        168,
        30
      ]
    ],
    "num_no_hallucination": 1802,
    "num_hallucination": 198
  },
  "training_history": {
    "train_loss": [
      0.48650418788194655,
      0.3267598887681961,
      0.3075775828063488,
      0.293610016644001,
      0.2837869817018509,
      0.27335703566670416,
      0.2657398127615452,
      0.2631421267688274,
      0.25539240017533305,
      0.25356216007471083,
      0.24725807625055313,
      0.23955716481804848,
      0.23477790609002114,
      0.2335410255789757,
      0.22935061568021775,
      0.2272091142833233,
      0.22740000480413436,
      0.2217431998550892,
      0.22010774749517442,
      0.2154300898015499,
      0.21468015366792678,
      0.20951808962225915,
      0.2079517381489277,
      0.20454607525467872,
      0.20399357190728187,
      0.20225255864858627,
      0.19930667346715927,
      0.1999803217947483,
      0.19252230605483056,
      0.19422394433617593,
      0.1981065431535244,
      0.19140683540701867,
      0.18706853370368481,
      0.1898674665093422,
      0.19091413900256157,
      0.1838835735321045,
      0.18719343826174736,
      0.18572482562065123,
      0.1803440376371145,
      0.1834262247234583,
      0.1779106505960226,
      0.17364031194150448,
      0.17686540527641773,
      0.17723605616390706,
      0.17553401932120324,
      0.17655626776814462,
      0.17503449107706548,
      0.17421420377492905,
      0.17346344482898712,
      0.17424436950683594
    ],
    "train_acc": [
      0.795,
      0.895625,
      0.896375,
      0.89775,
      0.899,
      0.903125,
      0.90125,
      0.903375,
      0.903125,
      0.902375,
      0.905,
      0.903,
      0.907,
      0.9075,
      0.908375,
      0.90675,
      0.908875,
      0.90875,
      0.91025,
      0.908125,
      0.906875,
      0.909375,
      0.911,
      0.911375,
      0.909625,
      0.913875,
      0.910625,
      0.909375,
      0.913,
      0.913875,
      0.911875,
      0.91275,
      0.913875,
      0.915625,
      0.91375,
      0.9125,
      0.910625,
      0.917625,
      0.91475,
      0.912875,
      0.91475,
      0.917125,
      0.9165,
      0.91725,
      0.9165,
      0.91625,
      0.916875,
      0.91825,
      0.9175,
      0.91725
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Smol_VL/smolvlm_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/smolvlm_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/smolvlm_model_probe/results/vision_token_layer18",
    "MODEL_NAME": "SmolVLM2-2.2B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_18",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}