{
  "model_name": "SmolVLM2-2.2B",
  "embedding_type": "vision_token_representation",
  "layer_name": "layer_23",
  "target_column": "is_hallucinating_manual",
  "input_dim": 2048,
  "timestamp": "20251004_120306",
  "dataset_statistics": {
    "total_samples": 10000,
    "num_no_hallucination": 9009,
    "num_hallucination": 991,
    "hallucination_percentage": 9.91
  },
  "train_set": {
    "num_samples": 8000,
    "accuracy": 0.92175,
    "precision": 0.6827133479212254,
    "recall": 0.39344262295081966,
    "f1": 0.4992,
    "auroc": 0.9445339239505658,
    "confusion_matrix": [
      [
        7062,
        145
      ],
      [
        481,
        312
      ]
    ],
    "num_no_hallucination": 7207,
    "num_hallucination": 793
  },
  "test_set": {
    "num_samples": 2000,
    "accuracy": 0.8675,
    "precision": 0.24427480916030533,
    "recall": 0.16161616161616163,
    "f1": 0.1945288753799392,
    "auroc": 0.6893953407549412,
    "confusion_matrix": [
      [
        1703,
        99
      ],
      [
        166,
        32
      ]
    ],
    "num_no_hallucination": 1802,
    "num_hallucination": 198
  },
  "training_history": {
    "train_loss": [
      0.47855491989850996,
      0.32316631880402563,
      0.30533794167637823,
      0.28377126342058184,
      0.27621634393930433,
      0.26569482135772704,
      0.25667814975976944,
      0.2471024006307125,
      0.24824042677879332,
      0.24092380914092065,
      0.2355954439342022,
      0.22923963165283204,
      0.22891971454024315,
      0.22386072427034379,
      0.21730394068360329,
      0.2163025618493557,
      0.2130573252737522,
      0.20912266904115676,
      0.2077363914847374,
      0.20732001250982285,
      0.20477606213092803,
      0.20210601195693015,
      0.20287347882986068,
      0.20027783703804017,
      0.1959362784922123,
      0.19065750986337662,
      0.19683758242428304,
      0.1882111234366894,
      0.1896170554757118,
      0.1870261178612709,
      0.18446447214484216,
      0.18313178625702858,
      0.18433652487397195,
      0.18293113961815835,
      0.17667722082138063,
      0.1764404255002737,
      0.1753249883055687,
      0.1766424310952425,
      0.17660156643390656,
      0.17813581927120686,
      0.1724176376760006,
      0.17450048466026782,
      0.17098081569373608,
      0.16941134029626848,
      0.1684258277118206,
      0.17549206702411174,
      0.16897181536257266,
      0.16937323144078253,
      0.1666836913228035,
      0.1671746585071087
    ],
    "train_acc": [
      0.799,
      0.895,
      0.89775,
      0.901,
      0.90225,
      0.901625,
      0.902125,
      0.906625,
      0.906,
      0.905125,
      0.906875,
      0.908625,
      0.9075,
      0.910875,
      0.91025,
      0.908625,
      0.908375,
      0.908,
      0.907875,
      0.90925,
      0.91175,
      0.9115,
      0.909875,
      0.91425,
      0.916875,
      0.914,
      0.910625,
      0.9135,
      0.915625,
      0.9135,
      0.914875,
      0.914125,
      0.91625,
      0.917125,
      0.9175,
      0.918125,
      0.91875,
      0.919125,
      0.916125,
      0.91225,
      0.9155,
      0.9175,
      0.91925,
      0.917625,
      0.918875,
      0.91675,
      0.92175,
      0.920375,
      0.919625,
      0.9185
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/Smol_VL/smolvlm_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/smolvlm_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/smolvlm_model_probe/results/vision_token_layer23",
    "MODEL_NAME": "SmolVLM2-2.2B",
    "EMBEDDING_TYPE": "vision_token_representation",
    "LAYER_NAME": "layer_23",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}