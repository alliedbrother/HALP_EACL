{
  "model_name": "Llama-3.2-11B-Vision",
  "embedding_type": "query_token_representation",
  "layer_name": "layer_0",
  "target_column": "is_hallucinating_manual",
  "input_dim": 4096,
  "timestamp": "20251003_190625",
  "dataset_statistics": {
    "total_samples": 9767,
    "num_no_hallucination": 8838,
    "num_hallucination": 929,
    "hallucination_percentage": 9.511620763796458
  },
  "train_set": {
    "num_samples": 7813,
    "accuracy": 0.9153974145654679,
    "precision": 0.6722689075630253,
    "recall": 0.21534320323014805,
    "f1": 0.32619775739041795,
    "auroc": 0.9025103702448691,
    "confusion_matrix": [
      [
        6992,
        78
      ],
      [
        583,
        160
      ]
    ],
    "num_no_hallucination": 7070,
    "num_hallucination": 743
  },
  "test_set": {
    "num_samples": 1954,
    "accuracy": 0.9114636642784033,
    "precision": 0.6,
    "recall": 0.20967741935483872,
    "f1": 0.3107569721115538,
    "auroc": 0.8622813579526103,
    "confusion_matrix": [
      [
        1742,
        26
      ],
      [
        147,
        39
      ]
    ],
    "num_no_hallucination": 1768,
    "num_hallucination": 186
  },
  "training_history": {
    "train_loss": [
      0.30987902475254875,
      0.26180225805360446,
      0.2587634743780506,
      0.24789920590665876,
      0.24783308241440324,
      0.2443093546799251,
      0.24185017760919064,
      0.24167466774886967,
      0.24156305756495924,
      0.23873830674862376,
      0.2352952909104678,
      0.23928295234028174,
      0.23493890379156385,
      0.2333427389057315,
      0.2369283103821229,
      0.23389179630547155,
      0.23841391321347685,
      0.23198458521950002,
      0.2288739706940797,
      0.23238527481349147,
      0.23151230912427512,
      0.23095422907143223,
      0.22786213959358176,
      0.22465400975577685,
      0.225280125895325,
      0.22514344037187342,
      0.22540184745983202,
      0.22709056871886157,
      0.22627509681850064,
      0.22160851979742244,
      0.22210848456134602,
      0.22428332530722325,
      0.22634742162665542,
      0.22302565072872202,
      0.22539232893257724,
      0.22472279810783816,
      0.21813445120137565,
      0.219250304692862,
      0.213042797152029,
      0.21620747466780701,
      0.21603254774699407,
      0.21762452761129458,
      0.22039075159296698,
      0.216157009315734,
      0.21281659600077843,
      0.21482351081711906,
      0.22162761338511291,
      0.21496577205098405,
      0.21471349688208832,
      0.21515987801308534
    ],
    "train_acc": [
      0.8945347497760143,
      0.904390119032382,
      0.9051580698835274,
      0.9037501599897606,
      0.9046461026494305,
      0.9055420453091002,
      0.9052860616920517,
      0.9083578650966339,
      0.905926020734673,
      0.9065659797772943,
      0.9068219633943427,
      0.9068219633943427,
      0.9066939715858185,
      0.9070779470113912,
      0.9063099961602458,
      0.9096377831818764,
      0.905926020734673,
      0.9073339306284398,
      0.9078458978625368,
      0.9096377831818764,
      0.9091258159477793,
      0.9098937667989249,
      0.9089978241392551,
      0.9097657749904006,
      0.9105337258415461,
      0.9104057340330219,
      0.9102777422244976,
      0.9109177012671189,
      0.9110456930756432,
      0.9095097913733521,
      0.9124536029694099,
      0.9114296685012159,
      0.9113016766926917,
      0.9120696275438372,
      0.9105337258415461,
      0.9120696275438372,
      0.9125815947779342,
      0.9110456930756432,
      0.9109177012671189,
      0.9123256111608857,
      0.9116856521182645,
      0.9121976193523614,
      0.9133495456290798,
      0.9121976193523614,
      0.912965570203507,
      0.9138615128631767,
      0.9132215538205555,
      0.9113016766926917,
      0.9137335210546526,
      0.9148854473313708
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLama_32/llama_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llama32_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llama32_model_probe/results/query_token_layer0",
    "MODEL_NAME": "Llama-3.2-11B-Vision",
    "EMBEDDING_TYPE": "query_token_representation",
    "LAYER_NAME": "layer_0",
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}