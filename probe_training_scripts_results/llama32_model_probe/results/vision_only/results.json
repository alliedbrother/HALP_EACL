{
  "model_name": "Llama-3.2-11B-Vision",
  "embedding_type": "vision_only_representation",
  "layer_name": null,
  "target_column": "is_hallucinating_manual",
  "input_dim": 7680,
  "timestamp": "20251003_190043",
  "dataset_statistics": {
    "total_samples": 9767,
    "num_no_hallucination": 8838,
    "num_hallucination": 929,
    "hallucination_percentage": 9.511620763796458
  },
  "train_set": {
    "num_samples": 7813,
    "accuracy": 0.9137335210546526,
    "precision": 0.7065868263473054,
    "recall": 0.15881561238223418,
    "f1": 0.25934065934065936,
    "auroc": 0.8998662671496913,
    "confusion_matrix": [
      [
        7021,
        49
      ],
      [
        625,
        118
      ]
    ],
    "num_no_hallucination": 7070,
    "num_hallucination": 743
  },
  "test_set": {
    "num_samples": 1954,
    "accuracy": 0.9032753326509724,
    "precision": 0.4666666666666667,
    "recall": 0.11290322580645161,
    "f1": 0.18181818181818182,
    "auroc": 0.7703026930375128,
    "confusion_matrix": [
      [
        1744,
        24
      ],
      [
        165,
        21
      ]
    ],
    "num_no_hallucination": 1768,
    "num_hallucination": 186
  },
  "training_history": {
    "train_loss": [
      0.3401060063620003,
      0.2995644748210907,
      0.2932618606455472,
      0.29157545490532505,
      0.28865166814351567,
      0.28545011354952443,
      0.2821397571235287,
      0.27808175220781445,
      0.28161509785116934,
      0.27860558276273767,
      0.2708812047328268,
      0.274157746561936,
      0.2697933025201973,
      0.271463020997388,
      0.2693909309652387,
      0.2638201315488134,
      0.2658329815584786,
      0.26297380373794205,
      0.26049088683663585,
      0.2585108214191028,
      0.26414206766960574,
      0.26453790327115934,
      0.2595960425783177,
      0.2568231755373429,
      0.2543843137062326,
      0.25448183198364416,
      0.2539900604255345,
      0.25085441880688375,
      0.2563914370171878,
      0.2474553228641043,
      0.2511353259488028,
      0.25242412871852216,
      0.2463785676627743,
      0.24574473305624359,
      0.24632343227157788,
      0.24704193536724364,
      0.2442046064959497,
      0.24358694875726894,
      0.24271778412619416,
      0.24571717262876278,
      0.23760472405321745,
      0.24457591328085684,
      0.23788330483497405,
      0.24435477646029724,
      0.2383451515922741,
      0.23470353122268403,
      0.2358208671820407,
      0.23720334500682597,
      0.23226842874166917,
      0.23625272051716337
    ],
    "train_acc": [
      0.8859592986048893,
      0.9047740944579546,
      0.9047740944579546,
      0.9047740944579546,
      0.9049020862664789,
      0.9057980289261487,
      0.9050300780750032,
      0.9061820043517215,
      0.9054140535005759,
      0.9046461026494305,
      0.906949955202867,
      0.904390119032382,
      0.9060540125431973,
      0.90643798796877,
      0.9055420453091002,
      0.9052860616920517,
      0.9052860616920517,
      0.9049020862664789,
      0.9066939715858185,
      0.9056700371176245,
      0.9057980289261487,
      0.9066939715858185,
      0.9068219633943427,
      0.9077179060540126,
      0.9068219633943427,
      0.9073339306284398,
      0.9065659797772943,
      0.9078458978625368,
      0.9079738896710611,
      0.9088698323307308,
      0.9082298732881096,
      0.9079738896710611,
      0.9088698323307308,
      0.9077179060540126,
      0.9066939715858185,
      0.9092538077563036,
      0.9077179060540126,
      0.9083578650966339,
      0.9078458978625368,
      0.9105337258415461,
      0.9113016766926917,
      0.9092538077563036,
      0.9092538077563036,
      0.9097657749904006,
      0.9109177012671189,
      0.9098937667989249,
      0.9096377831818764,
      0.9096377831818764,
      0.9106617176500704,
      0.9095097913733521
    ]
  },
  "config": {
    "H5_DIR": "/root/akhil/HALP_EACL_Models/Models/LLama_32/llama_output",
    "CSV_PATH": "/root/akhil/FInal_CSV_Hallucination/llama32_manually_reviewed.csv",
    "OUTPUT_DIR": "/root/akhil/probe_training_scripts/llama32_model_probe/results/vision_only",
    "MODEL_NAME": "Llama-3.2-11B-Vision",
    "EMBEDDING_TYPE": "vision_only_representation",
    "LAYER_NAME": null,
    "TARGET_COLUMN": "is_hallucinating_manual",
    "LAYER_SIZES": [
      512,
      256,
      128
    ],
    "DROPOUT_RATE": 0.3,
    "LEARNING_RATE": 0.001,
    "BATCH_SIZE": 32,
    "EPOCHS": 50,
    "TEST_SIZE": 0.2,
    "RANDOM_STATE": 42,
    "DEVICE": "cuda"
  }
}